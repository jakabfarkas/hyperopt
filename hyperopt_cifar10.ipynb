{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_kis_hf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Eow8ZFpJY5",
        "outputId": "3d37455f-ccd5-41d9-a521-a1a9e5be995d"
      },
      "source": [
        "!pip3 install hyperas\n",
        "!pip3 install hyperopt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/04/34/87ad6ffb42df9c1fa9c4c906f65813d42ad70d68c66af4ffff048c228cd4/hyperas-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.0.8)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.2)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.6.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.4.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.5)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.11.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.18.5)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.5.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.10.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.0.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.6.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.3)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.10.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1->nbformat->hyperas) (4.4.2)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.9.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (5.1.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (5.3.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.18)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (20.0.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (20.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.0->notebook->jupyter->hyperas) (2.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.2.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (50.3.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n",
            "Installing collected packages: hyperas\n",
            "Successfully installed hyperas-0.4.1\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.18.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.5)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.11.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt) (4.41.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWubgKtLpcJ1"
      },
      "source": [
        "# import the libraries\n",
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJiROAXupP-_"
      },
      "source": [
        "# function to import the cifar10 data\n",
        "def data():\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  \n",
        "  num_classes = 10\n",
        "  \n",
        "  y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "  y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "  \n",
        "  # normalization\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "  \n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVH2m9EGpTtD"
      },
      "source": [
        "# function to create our model\n",
        "def create_model(x_train, y_train, x_test, y_test):\n",
        "    \n",
        "    from keras.layers import Layer\n",
        "    from keras import backend as K\n",
        "\n",
        "    class Swish(Layer):\n",
        "        def __init__(self, beta, **kwargs):\n",
        "            super(Swish, self).__init__(**kwargs)\n",
        "            self.beta = K.cast_to_floatx(beta)\n",
        "\n",
        "        def call(self, inputs):\n",
        "            return K.sigmoid(self.beta * inputs) * inputs\n",
        "\n",
        "        def get_config(self):\n",
        "            config = {'beta': float(self.beta)}\n",
        "            base_config = super(Swish, self).get_config()\n",
        "            return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "        def compute_output_shape(self, input_shape):\n",
        "            return input_shape\n",
        "    \n",
        "    # hyperparameters to optimize\n",
        "    layer1 = {{choice([16, 32, 64])}}\n",
        "    kernel1 = {{choice([3, 5])}}\n",
        "    maxpooling1 = {{choice([True, False])}}\n",
        "    layer2 = {{choice([32, 64, 128])}}\n",
        "    kernel2 = {{choice([3, 5])}}\n",
        "    maxpooling2 = {{choice([True, False])}}\n",
        "    layer3 = {{choice([512, 1024, 2048])}}\n",
        "    act = {{choice(['relu', 'leakyrelu', 'swish'])}}\n",
        "    optim = {{choice(['rmsprop', 'adam', 'sgd'])}}\n",
        "    n_batch = {{choice([64, 128, 256])}}\n",
        "    \n",
        "    if act == 'relu':\n",
        "        activation = keras.layers.ReLU()\n",
        "    elif act == 'leakyrelu':\n",
        "        activation = keras.layers.LeakyReLU()\n",
        "    elif act == 'swish':\n",
        "        activation = Swish(beta=0.3)\n",
        "    \n",
        "    # build the model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(layer1, (kernel1, kernel1), activation=activation, input_shape=(32, 32, 3)))\n",
        "    if (maxpooling1):\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(layer2, (kernel2, kernel2), activation=activation))\n",
        "    if (maxpooling2):\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(layer3, activation=activation))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(optimizer=optim,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, verbose=0)]\n",
        "    \n",
        "    # start learning\n",
        "    result = model.fit(x_train, y_train,\n",
        "              batch_size=n_batch,\n",
        "              epochs=100,\n",
        "              verbose=2,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=callbacks,\n",
        "              shuffle=True)\n",
        "\n",
        "    best_val_acc = np.amax(result.history['val_accuracy'])\n",
        "    \n",
        "    # save the result\n",
        "    with open('hyperas-cifar10-log.csv', 'a') as csv_file:\n",
        "      csv_file.write(str(layer1) + ';')\n",
        "      csv_file.write(str(kernel1) + ';')\n",
        "      csv_file.write(str(maxpooling1) + ';')\n",
        "      csv_file.write(str(layer2) + ';')\n",
        "      csv_file.write(str(kernel2) + ';')\n",
        "      csv_file.write(str(maxpooling2) + ';')\n",
        "      csv_file.write(str(layer3) + ';')\n",
        "      csv_file.write(str(act) + ';')\n",
        "      csv_file.write(str(optim) + ';')\n",
        "      csv_file.write(str(n_batch) + ';')\n",
        "      csv_file.write(str(best_val_acc) + '\\n')\n",
        "\n",
        "    return {'loss': -best_val_acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSzuV74AprYM"
      },
      "source": [
        "# create the csv output file\n",
        "with open('hyperas-cifar10-log.csv', 'w') as csv_file:\n",
        "  csv_file.write('layer1' + ';')\n",
        "  csv_file.write('kernel1' + ';')\n",
        "  csv_file.write('maxpooling1' + ';')\n",
        "  csv_file.write('layer2' + ';')\n",
        "  csv_file.write('kernel2' + ';')\n",
        "  csv_file.write('maxpooling2' + ';')\n",
        "  csv_file.write('layer3' + ';')\n",
        "  csv_file.write('act' + ';')\n",
        "  csv_file.write('optim' + ';')\n",
        "  csv_file.write('n_batch' + ';')\n",
        "  csv_file.write('best_val_acc' + '\\n')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnRn0hRsCPa3"
      },
      "source": [
        "# import the libraries for hyperparameter optimization\n",
        "import hyperas\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt5mtl-9CQ6H",
        "outputId": "0071ac46-0b27-4d88-8f4d-9476c4f6440c"
      },
      "source": [
        "# run the optimization\n",
        "best_run, best_model = optim.minimize(model=create_model,\n",
        "                                          data=data,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          max_evals=40,\n",
        "                                          notebook_name='5_kis_hf',\n",
        "                                          trials=Trials())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "try:\n",
            "    import keras\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import fashion_mnist\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, Flatten\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.callbacks import EarlyStopping\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import cifar10\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Layer\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import backend as K\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'layer1': hp.choice('layer1', [16, 32, 64]),\n",
            "        'kernel1': hp.choice('kernel1', [3, 5]),\n",
            "        'maxpooling1': hp.choice('maxpooling1', [True, False]),\n",
            "        'layer2': hp.choice('layer2', [32, 64, 128]),\n",
            "        'kernel1_1': hp.choice('kernel1_1', [3, 5]),\n",
            "        'maxpooling1_1': hp.choice('maxpooling1_1', [True, False]),\n",
            "        'layer3': hp.choice('layer3', [512, 1024, 2048]),\n",
            "        'act': hp.choice('act', ['relu', 'leakyrelu', 'swish']),\n",
            "        'optim': hp.choice('optim', ['rmsprop', 'adam', 'sgd']),\n",
            "        'n_batch': hp.choice('n_batch', [64, 128, 256]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
            "  3: \n",
            "  4: num_classes = 10\n",
            "  5: \n",
            "  6: y_train = keras.utils.to_categorical(y_train, num_classes)\n",
            "  7: y_test = keras.utils.to_categorical(y_test, num_classes)\n",
            "  8: \n",
            "  9: x_train = x_train.astype('float32')\n",
            " 10: x_test = x_test.astype('float32')\n",
            " 11: \n",
            " 12: x_train /= 255\n",
            " 13: x_test /= 255\n",
            " 14: \n",
            " 15: \n",
            " 16: \n",
            " 17: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:     \n",
            "   4: \n",
            "   5:     class Swish(Layer):\n",
            "   6:         def __init__(self, beta, **kwargs):\n",
            "   7:             super(Swish, self).__init__(**kwargs)\n",
            "   8:             self.beta = K.cast_to_floatx(beta)\n",
            "   9: \n",
            "  10:         def call(self, inputs):\n",
            "  11:             return K.sigmoid(self.beta * inputs) * inputs\n",
            "  12: \n",
            "  13:         def get_config(self):\n",
            "  14:             config = {'beta': float(self.beta)}\n",
            "  15:             base_config = super(Swish, self).get_config()\n",
            "  16:             return dict(list(base_config.items()) + list(config.items()))\n",
            "  17: \n",
            "  18:         def compute_output_shape(self, input_shape):\n",
            "  19:             return input_shape\n",
            "  20:     \n",
            "  21:     layer1 = space['layer1']\n",
            "  22:     kernel1 = space['kernel1']\n",
            "  23:     maxpooling1 = space['maxpooling1']\n",
            "  24:     layer2 = space['layer2']\n",
            "  25:     kernel2 = space['kernel1_1']\n",
            "  26:     maxpooling2 = space['maxpooling1_1']\n",
            "  27:     layer3 = space['layer3']\n",
            "  28:     act = space['act']\n",
            "  29:     optim = space['optim']\n",
            "  30:     n_batch = space['n_batch']\n",
            "  31:     \n",
            "  32:     if act == 'relu':\n",
            "  33:         activation = keras.layers.ReLU()\n",
            "  34:     elif act == 'leakyrelu':\n",
            "  35:         activation = keras.layers.LeakyReLU()\n",
            "  36:     elif act == 'swish':\n",
            "  37:         activation = Swish(beta=0.3)\n",
            "  38:     \n",
            "  39:     model = Sequential()\n",
            "  40:     model.add(Conv2D(layer1, (kernel1, kernel1), activation=activation, input_shape=(32, 32, 3)))\n",
            "  41:     if (maxpooling1):\n",
            "  42:         model.add(MaxPooling2D((2, 2)))\n",
            "  43:     model.add(Conv2D(layer2, (kernel2, kernel2), activation=activation))\n",
            "  44:     if (maxpooling2):\n",
            "  45:         model.add(MaxPooling2D((2, 2)))\n",
            "  46:     model.add(Flatten())\n",
            "  47:     model.add(Dense(layer3, activation=activation))\n",
            "  48:     model.add(Dense(10, activation='softmax'))\n",
            "  49:     \n",
            "  50:     model.compile(optimizer=optim,\n",
            "  51:                   loss='categorical_crossentropy',\n",
            "  52:                   metrics=['accuracy'])\n",
            "  53: \n",
            "  54:     callbacks = [EarlyStopping(monitor='val_accuracy', patience=3, verbose=0)]\n",
            "  55:     \n",
            "  56:     result = model.fit(x_train, y_train,\n",
            "  57:               batch_size=n_batch,\n",
            "  58:               epochs=100,\n",
            "  59:               verbose=2,\n",
            "  60:               validation_data=(x_test, y_test),\n",
            "  61:               callbacks=callbacks,\n",
            "  62:               shuffle=True)\n",
            "  63: \n",
            "  64:     \n",
            "  65:     best_val_acc = np.amax(result.history['val_accuracy'])\n",
            "  66:     \n",
            "  67:     with open('hyperas-cifar10-log.csv', 'a') as csv_file:\n",
            "  68:       csv_file.write(str(layer1) + ';')\n",
            "  69:       csv_file.write(str(kernel1) + ';')\n",
            "  70:       csv_file.write(str(maxpooling1) + ';')\n",
            "  71:       csv_file.write(str(layer2) + ';')\n",
            "  72:       csv_file.write(str(kernel2) + ';')\n",
            "  73:       csv_file.write(str(maxpooling2) + ';')\n",
            "  74:       csv_file.write(str(layer3) + ';')\n",
            "  75:       csv_file.write(str(act) + ';')\n",
            "  76:       csv_file.write(str(optim) + ';')\n",
            "  77:       csv_file.write(str(n_batch) + ';')\n",
            "  78:       csv_file.write(str(best_val_acc) + '\\n')\n",
            "  79: \n",
            "  80:     return {'loss': -best_val_acc, 'status': STATUS_OK, 'model': model}\n",
            "  81: \n",
            "  0%|          | 0/40 [00:00<?, ?it/s, best loss: ?]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3aa71570f0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3aa71570f0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3aa71570f0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3aa71570f0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Epoch 1/100\n",
            "391/391 - 3s - loss: 2.2933 - accuracy: 0.1136 - val_loss: 2.2815 - val_accuracy: 0.1341\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 3s - loss: 2.2605 - accuracy: 0.1581 - val_loss: 2.2286 - val_accuracy: 0.2164\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 3s - loss: 2.1657 - accuracy: 0.2379 - val_loss: 2.0979 - val_accuracy: 0.2718\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 3s - loss: 2.0340 - accuracy: 0.2935 - val_loss: 1.9689 - val_accuracy: 0.3118\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 3s - loss: 1.9383 - accuracy: 0.3196 - val_loss: 1.9021 - val_accuracy: 0.3370\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 3s - loss: 1.8836 - accuracy: 0.3392 - val_loss: 1.8442 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 3s - loss: 1.8375 - accuracy: 0.3549 - val_loss: 1.8137 - val_accuracy: 0.3544\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 3s - loss: 1.7909 - accuracy: 0.3749 - val_loss: 1.8018 - val_accuracy: 0.3668\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 3s - loss: 1.7456 - accuracy: 0.3903 - val_loss: 1.7060 - val_accuracy: 0.4081\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 3s - loss: 1.7007 - accuracy: 0.4066 - val_loss: 1.6735 - val_accuracy: 0.4158\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 3s - loss: 1.6580 - accuracy: 0.4181 - val_loss: 1.6361 - val_accuracy: 0.4167\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 3s - loss: 1.6190 - accuracy: 0.4307 - val_loss: 1.6331 - val_accuracy: 0.4114\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 3s - loss: 1.5880 - accuracy: 0.4406 - val_loss: 1.5617 - val_accuracy: 0.4458\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 3s - loss: 1.5623 - accuracy: 0.4501 - val_loss: 1.5516 - val_accuracy: 0.4531\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 3s - loss: 1.5351 - accuracy: 0.4595 - val_loss: 1.5082 - val_accuracy: 0.4639\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 3s - loss: 1.5151 - accuracy: 0.4674 - val_loss: 1.5125 - val_accuracy: 0.4682\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 3s - loss: 1.4920 - accuracy: 0.4763 - val_loss: 1.4898 - val_accuracy: 0.4759\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 3s - loss: 1.4722 - accuracy: 0.4824 - val_loss: 1.4829 - val_accuracy: 0.4795\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 3s - loss: 1.4549 - accuracy: 0.4899 - val_loss: 1.4499 - val_accuracy: 0.4895\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 3s - loss: 1.4384 - accuracy: 0.4954 - val_loss: 1.4543 - val_accuracy: 0.4937\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 3s - loss: 1.4187 - accuracy: 0.5043 - val_loss: 1.4337 - val_accuracy: 0.4976\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 3s - loss: 1.4053 - accuracy: 0.5080 - val_loss: 1.4036 - val_accuracy: 0.5106\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 3s - loss: 1.3884 - accuracy: 0.5161 - val_loss: 1.3936 - val_accuracy: 0.5050\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 3s - loss: 1.3696 - accuracy: 0.5208 - val_loss: 1.3795 - val_accuracy: 0.5078\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 3s - loss: 1.3570 - accuracy: 0.5273 - val_loss: 1.4219 - val_accuracy: 0.4916\n",
            "\n",
            "  2%|▎         | 1/40 [01:27<57:08, 87.92s/it, best loss: -0.5105999708175659]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a4a35fdd8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a4a35fdd8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a4a35fdd8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a4a35fdd8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Epoch 1/100\n",
            "  2%|▎         | 1/40 [01:28<57:08, 87.92s/it, best loss: -0.5105999708175659]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0101s vs `on_train_batch_end` time: 0.0169s). Check your callbacks.\n",
            "196/196 - 6s - loss: 2.1892 - accuracy: 0.3083 - val_loss: 2.0170 - val_accuracy: 0.3172\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 6s - loss: 1.7097 - accuracy: 0.4064 - val_loss: 1.5959 - val_accuracy: 0.4378\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 6s - loss: 1.5744 - accuracy: 0.4619 - val_loss: 1.6025 - val_accuracy: 0.4451\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 6s - loss: 1.4578 - accuracy: 0.5006 - val_loss: 1.4778 - val_accuracy: 0.4913\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 6s - loss: 1.3894 - accuracy: 0.5249 - val_loss: 1.4105 - val_accuracy: 0.5124\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 6s - loss: 1.3239 - accuracy: 0.5460 - val_loss: 1.4086 - val_accuracy: 0.5221\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 6s - loss: 1.2737 - accuracy: 0.5604 - val_loss: 1.3538 - val_accuracy: 0.5355\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 6s - loss: 1.2238 - accuracy: 0.5802 - val_loss: 1.3018 - val_accuracy: 0.5484\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 6s - loss: 1.1653 - accuracy: 0.5993 - val_loss: 1.2841 - val_accuracy: 0.5629\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 6s - loss: 1.1137 - accuracy: 0.6163 - val_loss: 1.3631 - val_accuracy: 0.5315\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 6s - loss: 1.0505 - accuracy: 0.6375 - val_loss: 1.3995 - val_accuracy: 0.5336\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 6s - loss: 0.9919 - accuracy: 0.6579 - val_loss: 1.2386 - val_accuracy: 0.5749\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 6s - loss: 0.9318 - accuracy: 0.6777 - val_loss: 1.1714 - val_accuracy: 0.6148\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 6s - loss: 0.8720 - accuracy: 0.6977 - val_loss: 1.1808 - val_accuracy: 0.6147\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 6s - loss: 0.8051 - accuracy: 0.7223 - val_loss: 1.1108 - val_accuracy: 0.6289\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 6s - loss: 0.7259 - accuracy: 0.7508 - val_loss: 1.2279 - val_accuracy: 0.6307\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 6s - loss: 0.6455 - accuracy: 0.7778 - val_loss: 1.3910 - val_accuracy: 0.6164\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 6s - loss: 0.5616 - accuracy: 0.8056 - val_loss: 1.1733 - val_accuracy: 0.6662\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 6s - loss: 0.4689 - accuracy: 0.8374 - val_loss: 1.2647 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 6s - loss: 0.3750 - accuracy: 0.8710 - val_loss: 1.4119 - val_accuracy: 0.6497\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 6s - loss: 0.2856 - accuracy: 0.9022 - val_loss: 1.4313 - val_accuracy: 0.6671\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 6s - loss: 0.2111 - accuracy: 0.9287 - val_loss: 1.6561 - val_accuracy: 0.6622\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 6s - loss: 0.1527 - accuracy: 0.9477 - val_loss: 1.9593 - val_accuracy: 0.6629\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 6s - loss: 0.1153 - accuracy: 0.9613 - val_loss: 2.1990 - val_accuracy: 0.6439\n",
            "\n",
            "Epoch 1/100\n",
            "196/196 - 2s - loss: 1.4526 - accuracy: 0.4817 - val_loss: 1.1950 - val_accuracy: 0.5745\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 2s - loss: 1.0856 - accuracy: 0.6195 - val_loss: 1.0757 - val_accuracy: 0.6269\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 2s - loss: 0.9323 - accuracy: 0.6748 - val_loss: 0.9925 - val_accuracy: 0.6549\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 2s - loss: 0.8306 - accuracy: 0.7127 - val_loss: 0.9418 - val_accuracy: 0.6734\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 2s - loss: 0.7396 - accuracy: 0.7435 - val_loss: 1.0073 - val_accuracy: 0.6617\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 2s - loss: 0.6536 - accuracy: 0.7723 - val_loss: 0.8948 - val_accuracy: 0.6989\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 2s - loss: 0.5725 - accuracy: 0.8035 - val_loss: 0.9123 - val_accuracy: 0.7003\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 2s - loss: 0.4963 - accuracy: 0.8277 - val_loss: 0.9284 - val_accuracy: 0.7026\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 2s - loss: 0.4252 - accuracy: 0.8545 - val_loss: 1.0098 - val_accuracy: 0.6903\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 2s - loss: 0.3632 - accuracy: 0.8754 - val_loss: 1.0823 - val_accuracy: 0.6905\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 2s - loss: 0.3094 - accuracy: 0.8929 - val_loss: 1.1176 - val_accuracy: 0.6912\n",
            "\n",
            "Epoch 1/100\n",
            "  8%|▊         | 3/40 [04:12<49:15, 79.87s/it, best loss: -0.7026000022888184]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0058s vs `on_train_batch_end` time: 0.0140s). Check your callbacks.\n",
            "391/391 - 9s - loss: 1.5284 - accuracy: 0.4536 - val_loss: 1.3204 - val_accuracy: 0.5286\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 8s - loss: 1.1686 - accuracy: 0.5862 - val_loss: 1.1959 - val_accuracy: 0.5744\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 8s - loss: 0.9244 - accuracy: 0.6773 - val_loss: 1.1339 - val_accuracy: 0.6070\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 8s - loss: 0.6337 - accuracy: 0.7814 - val_loss: 1.2176 - val_accuracy: 0.6145\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 8s - loss: 0.3245 - accuracy: 0.8921 - val_loss: 1.4261 - val_accuracy: 0.6134\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 8s - loss: 0.1494 - accuracy: 0.9521 - val_loss: 1.7048 - val_accuracy: 0.6110\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 8s - loss: 0.0771 - accuracy: 0.9770 - val_loss: 2.1204 - val_accuracy: 0.6134\n",
            "\n",
            "Epoch 1/100\n",
            " 10%|█         | 4/40 [05:12<44:23, 73.99s/it, best loss: -0.7026000022888184]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0178s vs `on_train_batch_end` time: 0.0606s). Check your callbacks.\n",
            "196/196 - 16s - loss: 2.7323 - accuracy: 0.3125 - val_loss: 1.6877 - val_accuracy: 0.3958\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 16s - loss: 1.2967 - accuracy: 0.5497 - val_loss: 1.1727 - val_accuracy: 0.5910\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 16s - loss: 0.9168 - accuracy: 0.6867 - val_loss: 1.3555 - val_accuracy: 0.5753\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 16s - loss: 0.5390 - accuracy: 0.8172 - val_loss: 1.6372 - val_accuracy: 0.5388\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 16s - loss: 0.2385 - accuracy: 0.9214 - val_loss: 1.2984 - val_accuracy: 0.6661\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 16s - loss: 0.1235 - accuracy: 0.9643 - val_loss: 1.6725 - val_accuracy: 0.6683\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 16s - loss: 0.0888 - accuracy: 0.9752 - val_loss: 1.8768 - val_accuracy: 0.6720\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 16s - loss: 0.0498 - accuracy: 0.9856 - val_loss: 2.4531 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 16s - loss: 0.0442 - accuracy: 0.9876 - val_loss: 2.3235 - val_accuracy: 0.6583\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 16s - loss: 0.0593 - accuracy: 0.9860 - val_loss: 2.4382 - val_accuracy: 0.6682\n",
            "\n",
            " 12%|█▎        | 5/40 [07:55<58:45, 100.74s/it, best loss: -0.7026000022888184]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a4268d550>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a4268d550>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a4268d550>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a4268d550>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Epoch 1/100\n",
            "196/196 - 2s - loss: 2.2998 - accuracy: 0.1343 - val_loss: 2.2956 - val_accuracy: 0.1361\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 2s - loss: 2.2909 - accuracy: 0.1383 - val_loss: 2.2844 - val_accuracy: 0.1235\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 2s - loss: 2.2757 - accuracy: 0.1392 - val_loss: 2.2637 - val_accuracy: 0.1488\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 2s - loss: 2.2440 - accuracy: 0.1742 - val_loss: 2.2169 - val_accuracy: 0.2071\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 2s - loss: 2.1701 - accuracy: 0.2243 - val_loss: 2.1162 - val_accuracy: 0.2505\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 2s - loss: 2.0646 - accuracy: 0.2654 - val_loss: 2.0231 - val_accuracy: 0.2758\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 2s - loss: 1.9974 - accuracy: 0.2912 - val_loss: 2.0148 - val_accuracy: 0.2875\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 2s - loss: 1.9644 - accuracy: 0.3050 - val_loss: 1.9498 - val_accuracy: 0.3125\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 2s - loss: 1.9364 - accuracy: 0.3183 - val_loss: 1.9637 - val_accuracy: 0.2941\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 2s - loss: 1.9067 - accuracy: 0.3309 - val_loss: 1.8926 - val_accuracy: 0.3298\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 2s - loss: 1.8776 - accuracy: 0.3404 - val_loss: 1.8462 - val_accuracy: 0.3484\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 2s - loss: 1.8348 - accuracy: 0.3559 - val_loss: 1.8139 - val_accuracy: 0.3543\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 2s - loss: 1.7985 - accuracy: 0.3686 - val_loss: 1.7682 - val_accuracy: 0.3713\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 2s - loss: 1.7479 - accuracy: 0.3850 - val_loss: 1.7225 - val_accuracy: 0.3834\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 2s - loss: 1.7155 - accuracy: 0.3960 - val_loss: 1.6758 - val_accuracy: 0.4085\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 2s - loss: 1.6833 - accuracy: 0.4044 - val_loss: 1.6469 - val_accuracy: 0.4147\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 2s - loss: 1.6481 - accuracy: 0.4197 - val_loss: 1.6249 - val_accuracy: 0.4130\n",
            "\n",
            "Epoch 18/100\n",
            "196/196 - 2s - loss: 1.6239 - accuracy: 0.4302 - val_loss: 1.6262 - val_accuracy: 0.4212\n",
            "\n",
            "Epoch 19/100\n",
            "196/196 - 2s - loss: 1.5999 - accuracy: 0.4383 - val_loss: 1.6180 - val_accuracy: 0.4200\n",
            "\n",
            "Epoch 20/100\n",
            "196/196 - 2s - loss: 1.5716 - accuracy: 0.4488 - val_loss: 1.5959 - val_accuracy: 0.4352\n",
            "\n",
            "Epoch 21/100\n",
            "196/196 - 2s - loss: 1.5507 - accuracy: 0.4557 - val_loss: 1.6268 - val_accuracy: 0.4387\n",
            "\n",
            "Epoch 22/100\n",
            "196/196 - 2s - loss: 1.5342 - accuracy: 0.4620 - val_loss: 1.5312 - val_accuracy: 0.4554\n",
            "\n",
            "Epoch 23/100\n",
            "196/196 - 2s - loss: 1.5125 - accuracy: 0.4676 - val_loss: 1.6970 - val_accuracy: 0.4093\n",
            "\n",
            "Epoch 24/100\n",
            "196/196 - 2s - loss: 1.5029 - accuracy: 0.4711 - val_loss: 1.4806 - val_accuracy: 0.4773\n",
            "\n",
            "Epoch 25/100\n",
            "196/196 - 2s - loss: 1.4774 - accuracy: 0.4813 - val_loss: 1.4805 - val_accuracy: 0.4707\n",
            "\n",
            "Epoch 26/100\n",
            "196/196 - 2s - loss: 1.4618 - accuracy: 0.4856 - val_loss: 1.5941 - val_accuracy: 0.4358\n",
            "\n",
            "Epoch 27/100\n",
            "196/196 - 2s - loss: 1.4521 - accuracy: 0.4908 - val_loss: 1.5303 - val_accuracy: 0.4600\n",
            "\n",
            "Epoch 1/100\n",
            "782/782 - 4s - loss: 1.4436 - accuracy: 0.4877 - val_loss: 1.2036 - val_accuracy: 0.5812\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 4s - loss: 1.0358 - accuracy: 0.6370 - val_loss: 1.0510 - val_accuracy: 0.6285\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 4s - loss: 0.8912 - accuracy: 0.6911 - val_loss: 1.0933 - val_accuracy: 0.6246\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 4s - loss: 0.7845 - accuracy: 0.7283 - val_loss: 0.9920 - val_accuracy: 0.6616\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 4s - loss: 0.6950 - accuracy: 0.7596 - val_loss: 0.9995 - val_accuracy: 0.6685\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 4s - loss: 0.6193 - accuracy: 0.7861 - val_loss: 1.0091 - val_accuracy: 0.6750\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 4s - loss: 0.5514 - accuracy: 0.8094 - val_loss: 1.1880 - val_accuracy: 0.6507\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 4s - loss: 0.4882 - accuracy: 0.8300 - val_loss: 1.0886 - val_accuracy: 0.6743\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 4s - loss: 0.4340 - accuracy: 0.8485 - val_loss: 1.1613 - val_accuracy: 0.6770\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 4s - loss: 0.3795 - accuracy: 0.8681 - val_loss: 1.0466 - val_accuracy: 0.7038\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 4s - loss: 0.3333 - accuracy: 0.8828 - val_loss: 1.1159 - val_accuracy: 0.7030\n",
            "\n",
            "Epoch 12/100\n",
            "782/782 - 4s - loss: 0.2953 - accuracy: 0.8958 - val_loss: 1.3082 - val_accuracy: 0.6703\n",
            "\n",
            "Epoch 13/100\n",
            "782/782 - 4s - loss: 0.2574 - accuracy: 0.9093 - val_loss: 1.3573 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 1/100\n",
            " 18%|█▊        | 7/40 [09:37<41:26, 75.34s/it, best loss: -0.7038000226020813]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 0.0329s). Check your callbacks.\n",
            "391/391 - 22s - loss: 1.9694 - accuracy: 0.2958 - val_loss: 1.7859 - val_accuracy: 0.3727\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 22s - loss: 1.6855 - accuracy: 0.4052 - val_loss: 1.5848 - val_accuracy: 0.4468\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 22s - loss: 1.5291 - accuracy: 0.4622 - val_loss: 1.4521 - val_accuracy: 0.4908\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 22s - loss: 1.4016 - accuracy: 0.5067 - val_loss: 1.3744 - val_accuracy: 0.5179\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 22s - loss: 1.3132 - accuracy: 0.5386 - val_loss: 1.2974 - val_accuracy: 0.5422\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 22s - loss: 1.2457 - accuracy: 0.5651 - val_loss: 1.3505 - val_accuracy: 0.5289\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 22s - loss: 1.1773 - accuracy: 0.5897 - val_loss: 1.2689 - val_accuracy: 0.5548\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 22s - loss: 1.1151 - accuracy: 0.6127 - val_loss: 1.2102 - val_accuracy: 0.5761\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 22s - loss: 1.0542 - accuracy: 0.6348 - val_loss: 1.2341 - val_accuracy: 0.5678\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 22s - loss: 0.9879 - accuracy: 0.6605 - val_loss: 1.2306 - val_accuracy: 0.5731\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 22s - loss: 0.9221 - accuracy: 0.6845 - val_loss: 1.1436 - val_accuracy: 0.6016\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 22s - loss: 0.8519 - accuracy: 0.7100 - val_loss: 1.1768 - val_accuracy: 0.5937\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 22s - loss: 0.7750 - accuracy: 0.7372 - val_loss: 1.1772 - val_accuracy: 0.6003\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 22s - loss: 0.7014 - accuracy: 0.7649 - val_loss: 1.1462 - val_accuracy: 0.6174\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 22s - loss: 0.6246 - accuracy: 0.7912 - val_loss: 1.1989 - val_accuracy: 0.6066\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 22s - loss: 0.5476 - accuracy: 0.8186 - val_loss: 1.1729 - val_accuracy: 0.6170\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 22s - loss: 0.4691 - accuracy: 0.8487 - val_loss: 1.2265 - val_accuracy: 0.6188\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 22s - loss: 0.3959 - accuracy: 0.8744 - val_loss: 1.2659 - val_accuracy: 0.6155\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 22s - loss: 0.3150 - accuracy: 0.9048 - val_loss: 1.3143 - val_accuracy: 0.6114\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 22s - loss: 0.2573 - accuracy: 0.9255 - val_loss: 1.2974 - val_accuracy: 0.6297\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 22s - loss: 0.1945 - accuracy: 0.9471 - val_loss: 1.3716 - val_accuracy: 0.6214\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 22s - loss: 0.1378 - accuracy: 0.9687 - val_loss: 1.5508 - val_accuracy: 0.6075\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 22s - loss: 0.1040 - accuracy: 0.9788 - val_loss: 1.5268 - val_accuracy: 0.6241\n",
            "\n",
            "Epoch 1/100\n",
            " 20%|██        | 8/40 [18:04<1:49:17, 204.92s/it, best loss: -0.7038000226020813]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0149s vs `on_train_batch_end` time: 0.0233s). Check your callbacks.\n",
            "196/196 - 8s - loss: 2.1724 - accuracy: 0.3757 - val_loss: 1.4596 - val_accuracy: 0.4783\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 8s - loss: 1.3637 - accuracy: 0.5417 - val_loss: 1.1800 - val_accuracy: 0.5891\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 8s - loss: 1.1237 - accuracy: 0.6163 - val_loss: 1.2351 - val_accuracy: 0.5861\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 8s - loss: 0.9886 - accuracy: 0.6658 - val_loss: 1.1493 - val_accuracy: 0.6037\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 8s - loss: 0.8418 - accuracy: 0.7126 - val_loss: 1.1296 - val_accuracy: 0.6236\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 8s - loss: 0.7404 - accuracy: 0.7509 - val_loss: 1.0671 - val_accuracy: 0.6510\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 8s - loss: 0.5998 - accuracy: 0.7924 - val_loss: 1.7414 - val_accuracy: 0.5410\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 8s - loss: 0.4894 - accuracy: 0.8315 - val_loss: 1.2805 - val_accuracy: 0.6345\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 8s - loss: 0.4160 - accuracy: 0.8610 - val_loss: 1.2736 - val_accuracy: 0.6514\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 8s - loss: 0.3201 - accuracy: 0.8904 - val_loss: 1.5029 - val_accuracy: 0.6433\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 8s - loss: 0.2642 - accuracy: 0.9119 - val_loss: 1.5233 - val_accuracy: 0.6586\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 8s - loss: 0.2530 - accuracy: 0.9235 - val_loss: 1.9020 - val_accuracy: 0.6162\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 8s - loss: 0.2253 - accuracy: 0.9355 - val_loss: 1.9009 - val_accuracy: 0.6424\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 8s - loss: 0.1746 - accuracy: 0.9448 - val_loss: 1.9778 - val_accuracy: 0.6405\n",
            "\n",
            " 22%|██▎       | 9/40 [20:01<1:32:13, 178.51s/it, best loss: -0.7038000226020813]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a7dafd0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a7dafd0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a7dafd0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a7dafd0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Epoch 1/100\n",
            "782/782 - 11s - loss: 1.8266 - accuracy: 0.3699 - val_loss: 1.7350 - val_accuracy: 0.3940\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 11s - loss: 1.6366 - accuracy: 0.4289 - val_loss: 1.5973 - val_accuracy: 0.4355\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 11s - loss: 1.5015 - accuracy: 0.4758 - val_loss: 1.4716 - val_accuracy: 0.4809\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 11s - loss: 1.3844 - accuracy: 0.5178 - val_loss: 1.4477 - val_accuracy: 0.4904\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 11s - loss: 1.2630 - accuracy: 0.5568 - val_loss: 1.4190 - val_accuracy: 0.5096\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 11s - loss: 1.1381 - accuracy: 0.6017 - val_loss: 1.4484 - val_accuracy: 0.5095\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 11s - loss: 0.9638 - accuracy: 0.6609 - val_loss: 1.6352 - val_accuracy: 0.4879\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 11s - loss: 0.7577 - accuracy: 0.7344 - val_loss: 1.8073 - val_accuracy: 0.5011\n",
            "\n",
            "Epoch 1/100\n",
            "196/196 - 3s - loss: 1.5688 - accuracy: 0.4343 - val_loss: 1.3090 - val_accuracy: 0.5305\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 3s - loss: 1.2151 - accuracy: 0.5693 - val_loss: 1.1142 - val_accuracy: 0.6049\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 3s - loss: 1.0661 - accuracy: 0.6252 - val_loss: 1.1031 - val_accuracy: 0.6121\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 3s - loss: 0.9494 - accuracy: 0.6685 - val_loss: 0.9708 - val_accuracy: 0.6603\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 3s - loss: 0.8431 - accuracy: 0.7066 - val_loss: 0.9136 - val_accuracy: 0.6825\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 3s - loss: 0.7612 - accuracy: 0.7355 - val_loss: 0.8835 - val_accuracy: 0.6942\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 3s - loss: 0.6779 - accuracy: 0.7638 - val_loss: 0.9326 - val_accuracy: 0.6849\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 3s - loss: 0.6104 - accuracy: 0.7895 - val_loss: 0.9336 - val_accuracy: 0.6920\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 3s - loss: 0.5420 - accuracy: 0.8126 - val_loss: 0.8675 - val_accuracy: 0.7172\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 3s - loss: 0.4578 - accuracy: 0.8428 - val_loss: 0.8812 - val_accuracy: 0.7166\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 3s - loss: 0.3905 - accuracy: 0.8667 - val_loss: 0.9627 - val_accuracy: 0.7010\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 3s - loss: 0.3280 - accuracy: 0.8876 - val_loss: 1.0191 - val_accuracy: 0.7015\n",
            "\n",
            " 28%|██▊       | 11/40 [22:02<56:03, 115.98s/it, best loss: -0.717199981212616]   WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a446ac8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a446ac8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a446ac8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a446ac8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Epoch 1/100\n",
            "782/782 - 5s - loss: 1.4647 - accuracy: 0.4844 - val_loss: 1.2474 - val_accuracy: 0.5694\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 5s - loss: 1.1578 - accuracy: 0.6002 - val_loss: 1.1933 - val_accuracy: 0.5854\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 5s - loss: 1.0545 - accuracy: 0.6383 - val_loss: 1.0744 - val_accuracy: 0.6311\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 5s - loss: 0.9859 - accuracy: 0.6621 - val_loss: 1.0663 - val_accuracy: 0.6404\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 5s - loss: 0.9174 - accuracy: 0.6851 - val_loss: 1.0496 - val_accuracy: 0.6462\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 5s - loss: 0.8660 - accuracy: 0.6998 - val_loss: 1.0377 - val_accuracy: 0.6481\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 5s - loss: 0.8016 - accuracy: 0.7236 - val_loss: 0.9945 - val_accuracy: 0.6658\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 5s - loss: 0.7468 - accuracy: 0.7414 - val_loss: 1.0221 - val_accuracy: 0.6632\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 5s - loss: 0.6848 - accuracy: 0.7629 - val_loss: 1.0778 - val_accuracy: 0.6507\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 5s - loss: 0.6260 - accuracy: 0.7818 - val_loss: 1.0243 - val_accuracy: 0.6776\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 5s - loss: 0.5688 - accuracy: 0.8009 - val_loss: 1.0599 - val_accuracy: 0.6752\n",
            "\n",
            "Epoch 12/100\n",
            "782/782 - 5s - loss: 0.5032 - accuracy: 0.8234 - val_loss: 1.0932 - val_accuracy: 0.6775\n",
            "\n",
            "Epoch 13/100\n",
            "782/782 - 5s - loss: 0.4432 - accuracy: 0.8432 - val_loss: 1.1142 - val_accuracy: 0.6820\n",
            "\n",
            "Epoch 14/100\n",
            "782/782 - 5s - loss: 0.3854 - accuracy: 0.8641 - val_loss: 1.2031 - val_accuracy: 0.6788\n",
            "\n",
            "Epoch 15/100\n",
            "782/782 - 5s - loss: 0.3179 - accuracy: 0.8862 - val_loss: 1.2837 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 16/100\n",
            "782/782 - 5s - loss: 0.2601 - accuracy: 0.9086 - val_loss: 1.3415 - val_accuracy: 0.6868\n",
            "\n",
            "Epoch 17/100\n",
            "782/782 - 5s - loss: 0.2028 - accuracy: 0.9287 - val_loss: 1.4712 - val_accuracy: 0.6852\n",
            "\n",
            "Epoch 18/100\n",
            "782/782 - 5s - loss: 0.1596 - accuracy: 0.9442 - val_loss: 1.5571 - val_accuracy: 0.6913\n",
            "\n",
            "Epoch 19/100\n",
            "782/782 - 5s - loss: 0.1288 - accuracy: 0.9543 - val_loss: 1.7210 - val_accuracy: 0.6809\n",
            "\n",
            "Epoch 20/100\n",
            "782/782 - 5s - loss: 0.1031 - accuracy: 0.9640 - val_loss: 1.8704 - val_accuracy: 0.6936\n",
            "\n",
            "Epoch 21/100\n",
            "782/782 - 5s - loss: 0.0771 - accuracy: 0.9727 - val_loss: 2.0285 - val_accuracy: 0.6961\n",
            "\n",
            "Epoch 22/100\n",
            "782/782 - 5s - loss: 0.0843 - accuracy: 0.9709 - val_loss: 2.1660 - val_accuracy: 0.6685\n",
            "\n",
            "Epoch 23/100\n",
            "782/782 - 5s - loss: 0.0590 - accuracy: 0.9801 - val_loss: 2.3415 - val_accuracy: 0.6929\n",
            "\n",
            "Epoch 24/100\n",
            "782/782 - 5s - loss: 0.0507 - accuracy: 0.9826 - val_loss: 2.3944 - val_accuracy: 0.6902\n",
            "\n",
            "Epoch 1/100\n",
            " 30%|███       | 12/40 [24:08<55:28, 118.88s/it, best loss: -0.717199981212616]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0111s vs `on_train_batch_end` time: 0.0216s). Check your callbacks.\n",
            "196/196 - 7s - loss: 2.1956 - accuracy: 0.3476 - val_loss: 1.6089 - val_accuracy: 0.4259\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 7s - loss: 1.4273 - accuracy: 0.4928 - val_loss: 1.4135 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 7s - loss: 1.2125 - accuracy: 0.5752 - val_loss: 1.2060 - val_accuracy: 0.5692\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 7s - loss: 1.0535 - accuracy: 0.6287 - val_loss: 1.1083 - val_accuracy: 0.6175\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 7s - loss: 0.9219 - accuracy: 0.6763 - val_loss: 1.1474 - val_accuracy: 0.6059\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 7s - loss: 0.8117 - accuracy: 0.7159 - val_loss: 1.1147 - val_accuracy: 0.6219\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 7s - loss: 0.7068 - accuracy: 0.7517 - val_loss: 1.1360 - val_accuracy: 0.6287\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 7s - loss: 0.6116 - accuracy: 0.7851 - val_loss: 1.1732 - val_accuracy: 0.6270\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 7s - loss: 0.4893 - accuracy: 0.8316 - val_loss: 1.2331 - val_accuracy: 0.6346\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 7s - loss: 0.4131 - accuracy: 0.8554 - val_loss: 1.3373 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 7s - loss: 0.3342 - accuracy: 0.8836 - val_loss: 1.4312 - val_accuracy: 0.6291\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 7s - loss: 0.2737 - accuracy: 0.9042 - val_loss: 1.6003 - val_accuracy: 0.6191\n",
            "\n",
            "Epoch 1/100\n",
            " 32%|███▎      | 13/40 [25:37<49:27, 109.91s/it, best loss: -0.717199981212616]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0081s vs `on_train_batch_end` time: 0.0248s). Check your callbacks.\n",
            "391/391 - 14s - loss: 1.5347 - accuracy: 0.4742 - val_loss: 1.1374 - val_accuracy: 0.6001\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 14s - loss: 0.9280 - accuracy: 0.6795 - val_loss: 1.0096 - val_accuracy: 0.6539\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 14s - loss: 0.6075 - accuracy: 0.7911 - val_loss: 0.8750 - val_accuracy: 0.7174\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 14s - loss: 0.3252 - accuracy: 0.8907 - val_loss: 1.1529 - val_accuracy: 0.6770\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 14s - loss: 0.1465 - accuracy: 0.9531 - val_loss: 1.4959 - val_accuracy: 0.6811\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 14s - loss: 0.0810 - accuracy: 0.9751 - val_loss: 1.8170 - val_accuracy: 0.6782\n",
            "\n",
            " 35%|███▌      | 14/40 [27:00<44:09, 101.90s/it, best loss: -0.7174000144004822]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a101eb8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a101eb8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a101eb8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a3a101eb8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Epoch 1/100\n",
            " 35%|███▌      | 14/40 [27:00<44:09, 101.90s/it, best loss: -0.7174000144004822]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_train_batch_end` time: 0.0134s). Check your callbacks.\n",
            "782/782 - 16s - loss: 1.8553 - accuracy: 0.3619 - val_loss: 1.7983 - val_accuracy: 0.3790\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 15s - loss: 1.6367 - accuracy: 0.4263 - val_loss: 1.5901 - val_accuracy: 0.4404\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 15s - loss: 1.4783 - accuracy: 0.4791 - val_loss: 1.4437 - val_accuracy: 0.4974\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 15s - loss: 1.3540 - accuracy: 0.5238 - val_loss: 1.4584 - val_accuracy: 0.4910\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 15s - loss: 1.2286 - accuracy: 0.5674 - val_loss: 1.4570 - val_accuracy: 0.4982\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 15s - loss: 1.0978 - accuracy: 0.6137 - val_loss: 1.4414 - val_accuracy: 0.5133\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 15s - loss: 0.9007 - accuracy: 0.6818 - val_loss: 1.7110 - val_accuracy: 0.5145\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 15s - loss: 0.6756 - accuracy: 0.7652 - val_loss: 2.0434 - val_accuracy: 0.4949\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 15s - loss: 0.4419 - accuracy: 0.8483 - val_loss: 2.1760 - val_accuracy: 0.4978\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 15s - loss: 0.2755 - accuracy: 0.9080 - val_loss: 2.7331 - val_accuracy: 0.4886\n",
            "\n",
            " 38%|███▊      | 15/40 [29:36<49:13, 118.13s/it, best loss: -0.7174000144004822]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a347054e0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a347054e0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a347054e0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a347054e0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Epoch 1/100\n",
            "391/391 - 5s - loss: 1.5856 - accuracy: 0.4421 - val_loss: 1.3212 - val_accuracy: 0.5436\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 4s - loss: 1.2290 - accuracy: 0.5754 - val_loss: 1.1686 - val_accuracy: 0.5957\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 4s - loss: 1.0857 - accuracy: 0.6249 - val_loss: 1.1159 - val_accuracy: 0.6182\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 4s - loss: 1.0093 - accuracy: 0.6512 - val_loss: 1.0828 - val_accuracy: 0.6337\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 4s - loss: 0.9404 - accuracy: 0.6762 - val_loss: 1.0529 - val_accuracy: 0.6417\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 4s - loss: 0.8780 - accuracy: 0.6964 - val_loss: 1.0358 - val_accuracy: 0.6480\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 4s - loss: 0.7930 - accuracy: 0.7232 - val_loss: 1.0154 - val_accuracy: 0.6597\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 4s - loss: 0.7088 - accuracy: 0.7530 - val_loss: 1.0053 - val_accuracy: 0.6649\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 4s - loss: 0.6198 - accuracy: 0.7838 - val_loss: 1.0586 - val_accuracy: 0.6649\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 4s - loss: 0.5064 - accuracy: 0.8249 - val_loss: 1.0728 - val_accuracy: 0.6730\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 4s - loss: 0.3807 - accuracy: 0.8690 - val_loss: 1.1656 - val_accuracy: 0.6746\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 4s - loss: 0.2674 - accuracy: 0.9081 - val_loss: 1.3164 - val_accuracy: 0.6831\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 4s - loss: 0.1704 - accuracy: 0.9440 - val_loss: 1.5558 - val_accuracy: 0.6803\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 4s - loss: 0.1020 - accuracy: 0.9669 - val_loss: 1.7657 - val_accuracy: 0.6728\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 4s - loss: 0.0779 - accuracy: 0.9750 - val_loss: 2.0081 - val_accuracy: 0.6647\n",
            "\n",
            "Epoch 1/100\n",
            "391/391 - 4s - loss: 1.5471 - accuracy: 0.4501 - val_loss: 1.2569 - val_accuracy: 0.5459\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 4s - loss: 1.1197 - accuracy: 0.6013 - val_loss: 1.1506 - val_accuracy: 0.5976\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 4s - loss: 0.8708 - accuracy: 0.6952 - val_loss: 1.0886 - val_accuracy: 0.6219\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 4s - loss: 0.6012 - accuracy: 0.7937 - val_loss: 1.1248 - val_accuracy: 0.6318\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 4s - loss: 0.3293 - accuracy: 0.8897 - val_loss: 1.3079 - val_accuracy: 0.6298\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 4s - loss: 0.1437 - accuracy: 0.9555 - val_loss: 1.5360 - val_accuracy: 0.6390\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 4s - loss: 0.0692 - accuracy: 0.9802 - val_loss: 1.9161 - val_accuracy: 0.6259\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 4s - loss: 0.0553 - accuracy: 0.9836 - val_loss: 2.1084 - val_accuracy: 0.6250\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 4s - loss: 0.0534 - accuracy: 0.9833 - val_loss: 2.1702 - val_accuracy: 0.6304\n",
            "\n",
            "Epoch 1/100\n",
            "782/782 - 5s - loss: 1.5005 - accuracy: 0.4679 - val_loss: 1.5516 - val_accuracy: 0.4701\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 5s - loss: 1.0408 - accuracy: 0.6383 - val_loss: 1.0802 - val_accuracy: 0.6232\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 5s - loss: 0.8031 - accuracy: 0.7225 - val_loss: 1.0191 - val_accuracy: 0.6695\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 5s - loss: 0.6051 - accuracy: 0.7922 - val_loss: 1.0114 - val_accuracy: 0.6848\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 5s - loss: 0.4183 - accuracy: 0.8582 - val_loss: 1.2280 - val_accuracy: 0.6521\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 5s - loss: 0.2738 - accuracy: 0.9085 - val_loss: 1.5174 - val_accuracy: 0.6475\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 5s - loss: 0.1753 - accuracy: 0.9405 - val_loss: 1.5879 - val_accuracy: 0.6947\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 5s - loss: 0.1202 - accuracy: 0.9597 - val_loss: 1.8389 - val_accuracy: 0.6738\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 5s - loss: 0.0944 - accuracy: 0.9690 - val_loss: 1.9413 - val_accuracy: 0.6897\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 5s - loss: 0.0791 - accuracy: 0.9740 - val_loss: 2.0699 - val_accuracy: 0.6844\n",
            "\n",
            " 45%|████▌     | 18/40 [32:13<27:06, 73.92s/it, best loss: -0.7174000144004822]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a34279358>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a34279358>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a34279358>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a34279358>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Epoch 1/100\n",
            " 45%|████▌     | 18/40 [32:13<27:06, 73.92s/it, best loss: -0.7174000144004822]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.0106s). Check your callbacks.\n",
            "782/782 - 13s - loss: 1.6181 - accuracy: 0.4493 - val_loss: 1.4903 - val_accuracy: 0.4698\n",
            "\n",
            "Epoch 2/100\n",
            "782/782 - 13s - loss: 1.2355 - accuracy: 0.5725 - val_loss: 1.1912 - val_accuracy: 0.5864\n",
            "\n",
            "Epoch 3/100\n",
            "782/782 - 13s - loss: 1.1127 - accuracy: 0.6177 - val_loss: 1.1447 - val_accuracy: 0.6042\n",
            "\n",
            "Epoch 4/100\n",
            "782/782 - 13s - loss: 1.0178 - accuracy: 0.6501 - val_loss: 1.2186 - val_accuracy: 0.5953\n",
            "\n",
            "Epoch 5/100\n",
            "782/782 - 13s - loss: 0.9260 - accuracy: 0.6809 - val_loss: 1.1369 - val_accuracy: 0.6137\n",
            "\n",
            "Epoch 6/100\n",
            "782/782 - 13s - loss: 0.8286 - accuracy: 0.7124 - val_loss: 1.1079 - val_accuracy: 0.6347\n",
            "\n",
            "Epoch 7/100\n",
            "782/782 - 13s - loss: 0.7225 - accuracy: 0.7477 - val_loss: 1.2684 - val_accuracy: 0.6156\n",
            "\n",
            "Epoch 8/100\n",
            "782/782 - 13s - loss: 0.6081 - accuracy: 0.7884 - val_loss: 1.1388 - val_accuracy: 0.6670\n",
            "\n",
            "Epoch 9/100\n",
            "782/782 - 13s - loss: 0.4785 - accuracy: 0.8327 - val_loss: 1.6615 - val_accuracy: 0.5919\n",
            "\n",
            "Epoch 10/100\n",
            "782/782 - 13s - loss: 0.3527 - accuracy: 0.8767 - val_loss: 1.6120 - val_accuracy: 0.6573\n",
            "\n",
            "Epoch 11/100\n",
            "782/782 - 13s - loss: 0.2429 - accuracy: 0.9159 - val_loss: 1.9448 - val_accuracy: 0.6476\n",
            "\n",
            " 48%|████▊     | 19/40 [34:38<33:19, 95.24s/it, best loss: -0.7174000144004822]WARNING:tensorflow:AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a340a1ba8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a340a1ba8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a340a1ba8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unable to locate the source code of <bound method keras_fmin_fnct.<locals>.Swish.call of <temp_model.keras_fmin_fnct.<locals>.Swish object at 0x7f3a340a1ba8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Epoch 1/100\n",
            "196/196 - 4s - loss: 1.6188 - accuracy: 0.4235 - val_loss: 1.3398 - val_accuracy: 0.5258\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 3s - loss: 1.2502 - accuracy: 0.5672 - val_loss: 1.1962 - val_accuracy: 0.5863\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 3s - loss: 1.1403 - accuracy: 0.6078 - val_loss: 1.1381 - val_accuracy: 0.6105\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 3s - loss: 1.0754 - accuracy: 0.6300 - val_loss: 1.1013 - val_accuracy: 0.6212\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 3s - loss: 1.0055 - accuracy: 0.6550 - val_loss: 1.0940 - val_accuracy: 0.6303\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 3s - loss: 0.9542 - accuracy: 0.6753 - val_loss: 1.0508 - val_accuracy: 0.6399\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 3s - loss: 0.9066 - accuracy: 0.6897 - val_loss: 1.0313 - val_accuracy: 0.6552\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 3s - loss: 0.8552 - accuracy: 0.7083 - val_loss: 1.0472 - val_accuracy: 0.6538\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 3s - loss: 0.8152 - accuracy: 0.7220 - val_loss: 1.0460 - val_accuracy: 0.6524\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 3s - loss: 0.7775 - accuracy: 0.7341 - val_loss: 1.0120 - val_accuracy: 0.6635\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 3s - loss: 0.7280 - accuracy: 0.7523 - val_loss: 1.0301 - val_accuracy: 0.6613\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 3s - loss: 0.6827 - accuracy: 0.7655 - val_loss: 1.0616 - val_accuracy: 0.6560\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 3s - loss: 0.6488 - accuracy: 0.7771 - val_loss: 1.1299 - val_accuracy: 0.6492\n",
            "\n",
            "Epoch 1/100\n",
            "391/391 - 4s - loss: 1.6302 - accuracy: 0.4235 - val_loss: 1.4943 - val_accuracy: 0.4752\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 3s - loss: 1.1494 - accuracy: 0.5980 - val_loss: 1.1122 - val_accuracy: 0.6108\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 3s - loss: 0.9253 - accuracy: 0.6779 - val_loss: 0.9829 - val_accuracy: 0.6621\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 3s - loss: 0.7473 - accuracy: 0.7396 - val_loss: 0.9048 - val_accuracy: 0.6938\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 3s - loss: 0.5836 - accuracy: 0.7984 - val_loss: 0.8892 - val_accuracy: 0.7102\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 3s - loss: 0.4297 - accuracy: 0.8521 - val_loss: 1.0010 - val_accuracy: 0.6935\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 3s - loss: 0.2975 - accuracy: 0.8983 - val_loss: 1.0927 - val_accuracy: 0.6972\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 3s - loss: 0.1947 - accuracy: 0.9361 - val_loss: 1.2148 - val_accuracy: 0.7073\n",
            "\n",
            "Epoch 1/100\n",
            "391/391 - 2s - loss: 2.2041 - accuracy: 0.1994 - val_loss: 2.0180 - val_accuracy: 0.2623\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 2s - loss: 1.9261 - accuracy: 0.3100 - val_loss: 1.8170 - val_accuracy: 0.3743\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 2s - loss: 1.7705 - accuracy: 0.3715 - val_loss: 1.6913 - val_accuracy: 0.3951\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 2s - loss: 1.6381 - accuracy: 0.4160 - val_loss: 1.5659 - val_accuracy: 0.4381\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 2s - loss: 1.5522 - accuracy: 0.4456 - val_loss: 1.5151 - val_accuracy: 0.4542\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 2s - loss: 1.4855 - accuracy: 0.4734 - val_loss: 1.4431 - val_accuracy: 0.4883\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 2s - loss: 1.4297 - accuracy: 0.4937 - val_loss: 1.4151 - val_accuracy: 0.4856\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 2s - loss: 1.3877 - accuracy: 0.5066 - val_loss: 1.3555 - val_accuracy: 0.5217\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 2s - loss: 1.3473 - accuracy: 0.5257 - val_loss: 1.3344 - val_accuracy: 0.5203\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 2s - loss: 1.3098 - accuracy: 0.5402 - val_loss: 1.3028 - val_accuracy: 0.5415\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 2s - loss: 1.2740 - accuracy: 0.5512 - val_loss: 1.3217 - val_accuracy: 0.5255\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 2s - loss: 1.2411 - accuracy: 0.5650 - val_loss: 1.2675 - val_accuracy: 0.5487\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 2s - loss: 1.2098 - accuracy: 0.5759 - val_loss: 1.2720 - val_accuracy: 0.5442\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 2s - loss: 1.1780 - accuracy: 0.5883 - val_loss: 1.2978 - val_accuracy: 0.5375\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 2s - loss: 1.1520 - accuracy: 0.5981 - val_loss: 1.2153 - val_accuracy: 0.5779\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 2s - loss: 1.1247 - accuracy: 0.6095 - val_loss: 1.1910 - val_accuracy: 0.5756\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 2s - loss: 1.0981 - accuracy: 0.6193 - val_loss: 1.1591 - val_accuracy: 0.5976\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 2s - loss: 1.0736 - accuracy: 0.6276 - val_loss: 1.1914 - val_accuracy: 0.5801\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 2s - loss: 1.0482 - accuracy: 0.6384 - val_loss: 1.1485 - val_accuracy: 0.6007\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 2s - loss: 1.0229 - accuracy: 0.6462 - val_loss: 1.1378 - val_accuracy: 0.6053\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 2s - loss: 1.0020 - accuracy: 0.6533 - val_loss: 1.1062 - val_accuracy: 0.6095\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 2s - loss: 0.9781 - accuracy: 0.6647 - val_loss: 1.1142 - val_accuracy: 0.6144\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 2s - loss: 0.9552 - accuracy: 0.6695 - val_loss: 1.1309 - val_accuracy: 0.6044\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 2s - loss: 0.9339 - accuracy: 0.6810 - val_loss: 1.0667 - val_accuracy: 0.6290\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 2s - loss: 0.9140 - accuracy: 0.6850 - val_loss: 1.0579 - val_accuracy: 0.6322\n",
            "\n",
            "Epoch 26/100\n",
            "391/391 - 2s - loss: 0.8933 - accuracy: 0.6926 - val_loss: 1.0763 - val_accuracy: 0.6327\n",
            "\n",
            "Epoch 27/100\n",
            "391/391 - 2s - loss: 0.8721 - accuracy: 0.7022 - val_loss: 1.0823 - val_accuracy: 0.6292\n",
            "\n",
            "Epoch 28/100\n",
            "391/391 - 2s - loss: 0.8540 - accuracy: 0.7055 - val_loss: 1.0622 - val_accuracy: 0.6355\n",
            "\n",
            "Epoch 29/100\n",
            "391/391 - 2s - loss: 0.8308 - accuracy: 0.7161 - val_loss: 1.0412 - val_accuracy: 0.6422\n",
            "\n",
            "Epoch 30/100\n",
            "391/391 - 2s - loss: 0.8116 - accuracy: 0.7218 - val_loss: 1.1401 - val_accuracy: 0.6132\n",
            "\n",
            "Epoch 31/100\n",
            "391/391 - 2s - loss: 0.7913 - accuracy: 0.7292 - val_loss: 1.0773 - val_accuracy: 0.6291\n",
            "\n",
            "Epoch 32/100\n",
            "391/391 - 2s - loss: 0.7743 - accuracy: 0.7357 - val_loss: 1.0301 - val_accuracy: 0.6470\n",
            "\n",
            "Epoch 33/100\n",
            "391/391 - 2s - loss: 0.7546 - accuracy: 0.7417 - val_loss: 1.1990 - val_accuracy: 0.5963\n",
            "\n",
            "Epoch 34/100\n",
            "391/391 - 2s - loss: 0.7342 - accuracy: 0.7497 - val_loss: 1.0588 - val_accuracy: 0.6396\n",
            "\n",
            "Epoch 35/100\n",
            "391/391 - 2s - loss: 0.7179 - accuracy: 0.7554 - val_loss: 1.0151 - val_accuracy: 0.6581\n",
            "\n",
            "Epoch 36/100\n",
            "391/391 - 2s - loss: 0.6978 - accuracy: 0.7608 - val_loss: 1.0387 - val_accuracy: 0.6510\n",
            "\n",
            "Epoch 37/100\n",
            "391/391 - 2s - loss: 0.6821 - accuracy: 0.7674 - val_loss: 1.0238 - val_accuracy: 0.6511\n",
            "\n",
            "Epoch 38/100\n",
            "391/391 - 2s - loss: 0.6620 - accuracy: 0.7740 - val_loss: 1.0337 - val_accuracy: 0.6509\n",
            "\n",
            "Epoch 1/100\n",
            " 55%|█████▌    | 22/40 [37:09<20:35, 68.67s/it, best loss: -0.7174000144004822]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0085s vs `on_train_batch_end` time: 0.0228s). Check your callbacks.\n",
            "391/391 - 13s - loss: 1.8782 - accuracy: 0.3913 - val_loss: 1.3111 - val_accuracy: 0.5412\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 13s - loss: 1.1632 - accuracy: 0.5993 - val_loss: 1.3016 - val_accuracy: 0.5684\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 13s - loss: 0.8144 - accuracy: 0.7222 - val_loss: 1.1776 - val_accuracy: 0.6273\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 13s - loss: 0.5066 - accuracy: 0.8305 - val_loss: 1.0869 - val_accuracy: 0.6813\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 13s - loss: 0.2717 - accuracy: 0.9105 - val_loss: 1.4399 - val_accuracy: 0.6629\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 13s - loss: 0.1521 - accuracy: 0.9505 - val_loss: 2.1801 - val_accuracy: 0.5861\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 13s - loss: 0.1160 - accuracy: 0.9643 - val_loss: 1.7786 - val_accuracy: 0.6507\n",
            "\n",
            "Epoch 1/100\n",
            "196/196 - 3s - loss: 1.7870 - accuracy: 0.3645 - val_loss: 1.4186 - val_accuracy: 0.4804\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 2s - loss: 1.3032 - accuracy: 0.5431 - val_loss: 1.1896 - val_accuracy: 0.5859\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 2s - loss: 1.0870 - accuracy: 0.6222 - val_loss: 1.1288 - val_accuracy: 0.6127\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 2s - loss: 0.9242 - accuracy: 0.6795 - val_loss: 0.9745 - val_accuracy: 0.6637\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 2s - loss: 0.7859 - accuracy: 0.7271 - val_loss: 1.0200 - val_accuracy: 0.6542\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 2s - loss: 0.6657 - accuracy: 0.7704 - val_loss: 1.0126 - val_accuracy: 0.6691\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 2s - loss: 0.5361 - accuracy: 0.8150 - val_loss: 0.9042 - val_accuracy: 0.7096\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 2s - loss: 0.4211 - accuracy: 0.8565 - val_loss: 0.9236 - val_accuracy: 0.7084\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 2s - loss: 0.3102 - accuracy: 0.8971 - val_loss: 1.0700 - val_accuracy: 0.6892\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 2s - loss: 0.2243 - accuracy: 0.9281 - val_loss: 1.1445 - val_accuracy: 0.6917\n",
            "\n",
            "Epoch 1/100\n",
            " 60%|██████    | 24/40 [39:04<16:01, 60.11s/it, best loss: -0.7174000144004822]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0145s vs `on_train_batch_end` time: 0.0277s). Check your callbacks.\n",
            "391/391 - 15s - loss: 1.7724 - accuracy: 0.4437 - val_loss: 1.2880 - val_accuracy: 0.5525\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 15s - loss: 1.0057 - accuracy: 0.6520 - val_loss: 1.0259 - val_accuracy: 0.6500\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 15s - loss: 0.6980 - accuracy: 0.7595 - val_loss: 0.9541 - val_accuracy: 0.6877\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 15s - loss: 0.4265 - accuracy: 0.8532 - val_loss: 0.9960 - val_accuracy: 0.7006\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 15s - loss: 0.2186 - accuracy: 0.9275 - val_loss: 1.3854 - val_accuracy: 0.6631\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 15s - loss: 0.1110 - accuracy: 0.9641 - val_loss: 1.7415 - val_accuracy: 0.6958\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 15s - loss: 0.0728 - accuracy: 0.9774 - val_loss: 1.7433 - val_accuracy: 0.7033\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 15s - loss: 0.0541 - accuracy: 0.9831 - val_loss: 2.0498 - val_accuracy: 0.7073\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 15s - loss: 0.0496 - accuracy: 0.9849 - val_loss: 2.0936 - val_accuracy: 0.6976\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 15s - loss: 0.0397 - accuracy: 0.9870 - val_loss: 2.3766 - val_accuracy: 0.7096\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 15s - loss: 0.0459 - accuracy: 0.9870 - val_loss: 2.3433 - val_accuracy: 0.7162\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 15s - loss: 0.0391 - accuracy: 0.9896 - val_loss: 2.5951 - val_accuracy: 0.6877\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 15s - loss: 0.0388 - accuracy: 0.9895 - val_loss: 2.8815 - val_accuracy: 0.6903\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 15s - loss: 0.0363 - accuracy: 0.9903 - val_loss: 3.0336 - val_accuracy: 0.6935\n",
            "\n",
            "Epoch 1/100\n",
            "196/196 - 2s - loss: 1.5712 - accuracy: 0.4331 - val_loss: 1.2744 - val_accuracy: 0.5393\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 2s - loss: 1.2113 - accuracy: 0.5747 - val_loss: 1.1210 - val_accuracy: 0.6010\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 2s - loss: 1.0569 - accuracy: 0.6293 - val_loss: 1.0204 - val_accuracy: 0.6451\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 2s - loss: 0.9470 - accuracy: 0.6698 - val_loss: 1.0090 - val_accuracy: 0.6446\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 2s - loss: 0.8533 - accuracy: 0.7024 - val_loss: 0.9974 - val_accuracy: 0.6580\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 2s - loss: 0.7797 - accuracy: 0.7301 - val_loss: 0.9190 - val_accuracy: 0.6852\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 2s - loss: 0.6956 - accuracy: 0.7581 - val_loss: 0.9917 - val_accuracy: 0.6611\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 2s - loss: 0.6334 - accuracy: 0.7819 - val_loss: 0.9188 - val_accuracy: 0.6888\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 2s - loss: 0.5533 - accuracy: 0.8114 - val_loss: 0.9274 - val_accuracy: 0.6977\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 2s - loss: 0.4830 - accuracy: 0.8330 - val_loss: 0.9812 - val_accuracy: 0.6827\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 2s - loss: 0.4050 - accuracy: 0.8640 - val_loss: 0.9666 - val_accuracy: 0.7061\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 2s - loss: 0.3443 - accuracy: 0.8844 - val_loss: 1.0437 - val_accuracy: 0.6872\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 2s - loss: 0.2772 - accuracy: 0.9106 - val_loss: 1.0665 - val_accuracy: 0.6962\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 2s - loss: 0.2182 - accuracy: 0.9311 - val_loss: 1.0918 - val_accuracy: 0.7088\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 2s - loss: 0.1707 - accuracy: 0.9474 - val_loss: 1.1904 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 2s - loss: 0.1281 - accuracy: 0.9632 - val_loss: 1.2663 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 2s - loss: 0.0966 - accuracy: 0.9741 - val_loss: 1.3902 - val_accuracy: 0.6961\n",
            "\n",
            "Epoch 1/100\n",
            "196/196 - 3s - loss: 2.2480 - accuracy: 0.1805 - val_loss: 2.1817 - val_accuracy: 0.2064\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 3s - loss: 2.0642 - accuracy: 0.2671 - val_loss: 2.0321 - val_accuracy: 0.2674\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 3s - loss: 1.9610 - accuracy: 0.2996 - val_loss: 1.9142 - val_accuracy: 0.3204\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 3s - loss: 1.8862 - accuracy: 0.3304 - val_loss: 1.8438 - val_accuracy: 0.3553\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 3s - loss: 1.8158 - accuracy: 0.3567 - val_loss: 1.8001 - val_accuracy: 0.3464\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 3s - loss: 1.7531 - accuracy: 0.3815 - val_loss: 1.7222 - val_accuracy: 0.3965\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 3s - loss: 1.6880 - accuracy: 0.4017 - val_loss: 1.6848 - val_accuracy: 0.3907\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 3s - loss: 1.6304 - accuracy: 0.4229 - val_loss: 1.6181 - val_accuracy: 0.4182\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 3s - loss: 1.5846 - accuracy: 0.4386 - val_loss: 1.5537 - val_accuracy: 0.4463\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 3s - loss: 1.5365 - accuracy: 0.4563 - val_loss: 1.5079 - val_accuracy: 0.4639\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 3s - loss: 1.5041 - accuracy: 0.4649 - val_loss: 1.5117 - val_accuracy: 0.4633\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 3s - loss: 1.4786 - accuracy: 0.4774 - val_loss: 1.4439 - val_accuracy: 0.4856\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 3s - loss: 1.4472 - accuracy: 0.4887 - val_loss: 1.4887 - val_accuracy: 0.4679\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 3s - loss: 1.4251 - accuracy: 0.4967 - val_loss: 1.4787 - val_accuracy: 0.4807\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 3s - loss: 1.4009 - accuracy: 0.5084 - val_loss: 1.4430 - val_accuracy: 0.4778\n",
            "\n",
            "Epoch 1/100\n",
            " 68%|██████▊   | 27/40 [43:46<15:13, 70.25s/it, best loss: -0.7174000144004822]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0069s vs `on_train_batch_end` time: 0.0132s). Check your callbacks.\n",
            "391/391 - 9s - loss: 1.4313 - accuracy: 0.4911 - val_loss: 1.1353 - val_accuracy: 0.5992\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 8s - loss: 1.0042 - accuracy: 0.6482 - val_loss: 0.9811 - val_accuracy: 0.6579\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 8s - loss: 0.7862 - accuracy: 0.7271 - val_loss: 0.9042 - val_accuracy: 0.6839\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 8s - loss: 0.5803 - accuracy: 0.8015 - val_loss: 0.9452 - val_accuracy: 0.6946\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 8s - loss: 0.3607 - accuracy: 0.8770 - val_loss: 1.0366 - val_accuracy: 0.6866\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 8s - loss: 0.1878 - accuracy: 0.9390 - val_loss: 1.2378 - val_accuracy: 0.6875\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 8s - loss: 0.0863 - accuracy: 0.9745 - val_loss: 1.4165 - val_accuracy: 0.6976\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 8s - loss: 0.0553 - accuracy: 0.9839 - val_loss: 1.5485 - val_accuracy: 0.6983\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 8s - loss: 0.0446 - accuracy: 0.9872 - val_loss: 1.7385 - val_accuracy: 0.6866\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 8s - loss: 0.0499 - accuracy: 0.9848 - val_loss: 1.8369 - val_accuracy: 0.6732\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 8s - loss: 0.0538 - accuracy: 0.9829 - val_loss: 1.8066 - val_accuracy: 0.6845\n",
            "\n",
            "Epoch 1/100\n",
            "391/391 - 3s - loss: 2.1884 - accuracy: 0.2051 - val_loss: 2.0163 - val_accuracy: 0.2509\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 3s - loss: 1.9224 - accuracy: 0.3087 - val_loss: 1.8327 - val_accuracy: 0.3512\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 3s - loss: 1.7836 - accuracy: 0.3641 - val_loss: 1.7511 - val_accuracy: 0.3764\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 3s - loss: 1.6629 - accuracy: 0.4078 - val_loss: 1.5852 - val_accuracy: 0.4288\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 3s - loss: 1.5663 - accuracy: 0.4417 - val_loss: 1.5490 - val_accuracy: 0.4521\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 3s - loss: 1.5003 - accuracy: 0.4649 - val_loss: 1.4583 - val_accuracy: 0.4726\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 3s - loss: 1.4501 - accuracy: 0.4838 - val_loss: 1.4498 - val_accuracy: 0.4765\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 3s - loss: 1.3995 - accuracy: 0.5005 - val_loss: 1.3726 - val_accuracy: 0.5063\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 3s - loss: 1.3598 - accuracy: 0.5202 - val_loss: 1.3427 - val_accuracy: 0.5216\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 3s - loss: 1.3199 - accuracy: 0.5330 - val_loss: 1.3602 - val_accuracy: 0.5079\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 3s - loss: 1.2845 - accuracy: 0.5478 - val_loss: 1.3644 - val_accuracy: 0.5156\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 3s - loss: 1.2526 - accuracy: 0.5611 - val_loss: 1.2857 - val_accuracy: 0.5457\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 3s - loss: 1.2219 - accuracy: 0.5698 - val_loss: 1.2267 - val_accuracy: 0.5671\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 3s - loss: 1.1912 - accuracy: 0.5836 - val_loss: 1.2301 - val_accuracy: 0.5720\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 3s - loss: 1.1626 - accuracy: 0.5940 - val_loss: 1.2590 - val_accuracy: 0.5551\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 3s - loss: 1.1370 - accuracy: 0.6044 - val_loss: 1.2526 - val_accuracy: 0.5507\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 3s - loss: 1.1114 - accuracy: 0.6136 - val_loss: 1.2000 - val_accuracy: 0.5775\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 3s - loss: 1.0855 - accuracy: 0.6227 - val_loss: 1.1571 - val_accuracy: 0.5913\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 3s - loss: 1.0675 - accuracy: 0.6285 - val_loss: 1.2007 - val_accuracy: 0.5763\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 3s - loss: 1.0425 - accuracy: 0.6393 - val_loss: 1.1323 - val_accuracy: 0.6052\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 3s - loss: 1.0212 - accuracy: 0.6447 - val_loss: 1.1107 - val_accuracy: 0.6087\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 3s - loss: 0.9999 - accuracy: 0.6550 - val_loss: 1.0909 - val_accuracy: 0.6175\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 3s - loss: 0.9809 - accuracy: 0.6621 - val_loss: 1.0744 - val_accuracy: 0.6304\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 3s - loss: 0.9574 - accuracy: 0.6686 - val_loss: 1.1389 - val_accuracy: 0.6005\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 3s - loss: 0.9398 - accuracy: 0.6770 - val_loss: 1.0962 - val_accuracy: 0.6169\n",
            "\n",
            "Epoch 26/100\n",
            "391/391 - 3s - loss: 0.9234 - accuracy: 0.6825 - val_loss: 1.0566 - val_accuracy: 0.6326\n",
            "\n",
            "Epoch 27/100\n",
            "391/391 - 3s - loss: 0.8983 - accuracy: 0.6918 - val_loss: 1.0377 - val_accuracy: 0.6375\n",
            "\n",
            "Epoch 28/100\n",
            "391/391 - 3s - loss: 0.8817 - accuracy: 0.6966 - val_loss: 1.0351 - val_accuracy: 0.6428\n",
            "\n",
            "Epoch 29/100\n",
            "391/391 - 3s - loss: 0.8628 - accuracy: 0.7048 - val_loss: 1.0562 - val_accuracy: 0.6352\n",
            "\n",
            "Epoch 30/100\n",
            "391/391 - 3s - loss: 0.8430 - accuracy: 0.7106 - val_loss: 1.0998 - val_accuracy: 0.6207\n",
            "\n",
            "Epoch 31/100\n",
            "391/391 - 3s - loss: 0.8237 - accuracy: 0.7198 - val_loss: 1.0847 - val_accuracy: 0.6277\n",
            "\n",
            "Epoch 1/100\n",
            " 72%|███████▎  | 29/40 [47:00<15:24, 84.03s/it, best loss: -0.7174000144004822]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0163s vs `on_train_batch_end` time: 0.0250s). Check your callbacks.\n",
            "196/196 - 9s - loss: 4.0207 - accuracy: 0.2860 - val_loss: 1.7599 - val_accuracy: 0.3686\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 8s - loss: 2.0415 - accuracy: 0.4248 - val_loss: 1.6545 - val_accuracy: 0.4219\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 8s - loss: 1.9345 - accuracy: 0.4731 - val_loss: 1.3717 - val_accuracy: 0.5127\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 9s - loss: 1.5147 - accuracy: 0.5435 - val_loss: 1.2769 - val_accuracy: 0.5550\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 8s - loss: 1.2626 - accuracy: 0.5866 - val_loss: 1.1358 - val_accuracy: 0.6021\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 9s - loss: 1.1191 - accuracy: 0.6257 - val_loss: 1.6681 - val_accuracy: 0.4788\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 8s - loss: 1.0265 - accuracy: 0.6620 - val_loss: 1.0441 - val_accuracy: 0.6450\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 8s - loss: 0.9031 - accuracy: 0.6989 - val_loss: 1.1032 - val_accuracy: 0.6368\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 9s - loss: 0.8490 - accuracy: 0.7289 - val_loss: 1.2026 - val_accuracy: 0.6370\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 9s - loss: 0.7376 - accuracy: 0.7575 - val_loss: 1.1316 - val_accuracy: 0.6428\n",
            "\n",
            "Epoch 1/100\n",
            "391/391 - 4s - loss: 1.6852 - accuracy: 0.4051 - val_loss: 1.7719 - val_accuracy: 0.3852\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 3s - loss: 1.1669 - accuracy: 0.5954 - val_loss: 1.0567 - val_accuracy: 0.6248\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 3s - loss: 0.9391 - accuracy: 0.6737 - val_loss: 0.9832 - val_accuracy: 0.6593\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 3s - loss: 0.7617 - accuracy: 0.7361 - val_loss: 0.9754 - val_accuracy: 0.6651\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 3s - loss: 0.6051 - accuracy: 0.7888 - val_loss: 0.9612 - val_accuracy: 0.6842\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 3s - loss: 0.4556 - accuracy: 0.8438 - val_loss: 0.9777 - val_accuracy: 0.7018\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 3s - loss: 0.3163 - accuracy: 0.8934 - val_loss: 1.0724 - val_accuracy: 0.7011\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 3s - loss: 0.2050 - accuracy: 0.9322 - val_loss: 1.3095 - val_accuracy: 0.6984\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 3s - loss: 0.1336 - accuracy: 0.9568 - val_loss: 1.2643 - val_accuracy: 0.7036\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 3s - loss: 0.0909 - accuracy: 0.9702 - val_loss: 1.4380 - val_accuracy: 0.7132\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 3s - loss: 0.0686 - accuracy: 0.9787 - val_loss: 1.6353 - val_accuracy: 0.7014\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 3s - loss: 0.0528 - accuracy: 0.9835 - val_loss: 1.7585 - val_accuracy: 0.7008\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 3s - loss: 0.0471 - accuracy: 0.9849 - val_loss: 1.8617 - val_accuracy: 0.7002\n",
            "\n",
            "Epoch 1/100\n",
            "196/196 - 3s - loss: 1.6026 - accuracy: 0.4199 - val_loss: 1.3505 - val_accuracy: 0.5173\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 3s - loss: 1.2331 - accuracy: 0.5627 - val_loss: 1.1591 - val_accuracy: 0.5856\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 3s - loss: 1.0664 - accuracy: 0.6255 - val_loss: 1.0476 - val_accuracy: 0.6281\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 3s - loss: 0.9552 - accuracy: 0.6662 - val_loss: 1.0241 - val_accuracy: 0.6460\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 3s - loss: 0.8587 - accuracy: 0.7027 - val_loss: 0.9938 - val_accuracy: 0.6544\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 3s - loss: 0.7806 - accuracy: 0.7273 - val_loss: 0.8952 - val_accuracy: 0.6894\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 3s - loss: 0.7017 - accuracy: 0.7566 - val_loss: 0.8683 - val_accuracy: 0.6958\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 3s - loss: 0.6237 - accuracy: 0.7839 - val_loss: 0.9038 - val_accuracy: 0.6917\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 3s - loss: 0.5509 - accuracy: 0.8097 - val_loss: 0.8822 - val_accuracy: 0.7004\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 3s - loss: 0.4699 - accuracy: 0.8375 - val_loss: 0.9129 - val_accuracy: 0.6992\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 3s - loss: 0.4056 - accuracy: 0.8620 - val_loss: 0.9803 - val_accuracy: 0.7086\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 3s - loss: 0.3357 - accuracy: 0.8862 - val_loss: 0.9751 - val_accuracy: 0.7093\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 3s - loss: 0.2608 - accuracy: 0.9141 - val_loss: 1.0302 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 3s - loss: 0.2057 - accuracy: 0.9339 - val_loss: 1.0523 - val_accuracy: 0.7145\n",
            "\n",
            "Epoch 15/100\n",
            "196/196 - 3s - loss: 0.1586 - accuracy: 0.9497 - val_loss: 1.1713 - val_accuracy: 0.7083\n",
            "\n",
            "Epoch 16/100\n",
            "196/196 - 3s - loss: 0.1184 - accuracy: 0.9646 - val_loss: 1.2432 - val_accuracy: 0.7123\n",
            "\n",
            "Epoch 17/100\n",
            "196/196 - 3s - loss: 0.0918 - accuracy: 0.9732 - val_loss: 1.4084 - val_accuracy: 0.6975\n",
            "\n",
            "Epoch 1/100\n",
            "391/391 - 3s - loss: 2.0501 - accuracy: 0.2558 - val_loss: 1.8931 - val_accuracy: 0.3203\n",
            "\n",
            "Epoch 2/100\n",
            "391/391 - 3s - loss: 1.7894 - accuracy: 0.3678 - val_loss: 1.7121 - val_accuracy: 0.3926\n",
            "\n",
            "Epoch 3/100\n",
            "391/391 - 3s - loss: 1.6603 - accuracy: 0.4139 - val_loss: 1.6398 - val_accuracy: 0.4152\n",
            "\n",
            "Epoch 4/100\n",
            "391/391 - 3s - loss: 1.5550 - accuracy: 0.4513 - val_loss: 1.5486 - val_accuracy: 0.4522\n",
            "\n",
            "Epoch 5/100\n",
            "391/391 - 3s - loss: 1.4695 - accuracy: 0.4823 - val_loss: 1.4606 - val_accuracy: 0.4828\n",
            "\n",
            "Epoch 6/100\n",
            "391/391 - 3s - loss: 1.4011 - accuracy: 0.5086 - val_loss: 1.3816 - val_accuracy: 0.5106\n",
            "\n",
            "Epoch 7/100\n",
            "391/391 - 3s - loss: 1.3424 - accuracy: 0.5290 - val_loss: 1.3595 - val_accuracy: 0.5169\n",
            "\n",
            "Epoch 8/100\n",
            "391/391 - 3s - loss: 1.2917 - accuracy: 0.5487 - val_loss: 1.2902 - val_accuracy: 0.5479\n",
            "\n",
            "Epoch 9/100\n",
            "391/391 - 3s - loss: 1.2496 - accuracy: 0.5637 - val_loss: 1.2598 - val_accuracy: 0.5541\n",
            "\n",
            "Epoch 10/100\n",
            "391/391 - 3s - loss: 1.2112 - accuracy: 0.5780 - val_loss: 1.2344 - val_accuracy: 0.5719\n",
            "\n",
            "Epoch 11/100\n",
            "391/391 - 3s - loss: 1.1734 - accuracy: 0.5927 - val_loss: 1.2327 - val_accuracy: 0.5635\n",
            "\n",
            "Epoch 12/100\n",
            "391/391 - 3s - loss: 1.1376 - accuracy: 0.6069 - val_loss: 1.2302 - val_accuracy: 0.5706\n",
            "\n",
            "Epoch 13/100\n",
            "391/391 - 3s - loss: 1.1031 - accuracy: 0.6168 - val_loss: 1.1806 - val_accuracy: 0.5873\n",
            "\n",
            "Epoch 14/100\n",
            "391/391 - 3s - loss: 1.0723 - accuracy: 0.6288 - val_loss: 1.1586 - val_accuracy: 0.5967\n",
            "\n",
            "Epoch 15/100\n",
            "391/391 - 3s - loss: 1.0419 - accuracy: 0.6388 - val_loss: 1.1721 - val_accuracy: 0.5906\n",
            "\n",
            "Epoch 16/100\n",
            "391/391 - 3s - loss: 1.0141 - accuracy: 0.6504 - val_loss: 1.1678 - val_accuracy: 0.5900\n",
            "\n",
            "Epoch 17/100\n",
            "391/391 - 3s - loss: 0.9827 - accuracy: 0.6596 - val_loss: 1.1377 - val_accuracy: 0.5999\n",
            "\n",
            "Epoch 18/100\n",
            "391/391 - 3s - loss: 0.9555 - accuracy: 0.6688 - val_loss: 1.1294 - val_accuracy: 0.6029\n",
            "\n",
            "Epoch 19/100\n",
            "391/391 - 3s - loss: 0.9294 - accuracy: 0.6786 - val_loss: 1.1012 - val_accuracy: 0.6183\n",
            "\n",
            "Epoch 20/100\n",
            "391/391 - 3s - loss: 0.8980 - accuracy: 0.6878 - val_loss: 1.1275 - val_accuracy: 0.6110\n",
            "\n",
            "Epoch 21/100\n",
            "391/391 - 3s - loss: 0.8748 - accuracy: 0.7000 - val_loss: 1.1173 - val_accuracy: 0.6164\n",
            "\n",
            "Epoch 22/100\n",
            "391/391 - 3s - loss: 0.8490 - accuracy: 0.7078 - val_loss: 1.1119 - val_accuracy: 0.6236\n",
            "\n",
            "Epoch 23/100\n",
            "391/391 - 3s - loss: 0.8211 - accuracy: 0.7183 - val_loss: 1.0724 - val_accuracy: 0.6337\n",
            "\n",
            "Epoch 24/100\n",
            "391/391 - 3s - loss: 0.7975 - accuracy: 0.7276 - val_loss: 1.1035 - val_accuracy: 0.6253\n",
            "\n",
            "Epoch 25/100\n",
            "391/391 - 3s - loss: 0.7692 - accuracy: 0.7384 - val_loss: 1.0971 - val_accuracy: 0.6333\n",
            "\n",
            "Epoch 26/100\n",
            "391/391 - 3s - loss: 0.7444 - accuracy: 0.7449 - val_loss: 1.1410 - val_accuracy: 0.6196\n",
            "\n",
            "Epoch 1/100\n",
            " 82%|████████▎ | 33/40 [51:10<07:45, 66.48s/it, best loss: -0.7174000144004822]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0058s vs `on_train_batch_end` time: 0.0091s). Check your callbacks.\n",
            "196/196 - 4s - loss: 1.8090 - accuracy: 0.3626 - val_loss: 1.3580 - val_accuracy: 0.5115\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 3s - loss: 1.2552 - accuracy: 0.5635 - val_loss: 1.2731 - val_accuracy: 0.5587\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 3s - loss: 1.0226 - accuracy: 0.6453 - val_loss: 1.0606 - val_accuracy: 0.6308\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 3s - loss: 0.8542 - accuracy: 0.7047 - val_loss: 1.0159 - val_accuracy: 0.6562\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 3s - loss: 0.7078 - accuracy: 0.7551 - val_loss: 1.0293 - val_accuracy: 0.6556\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 3s - loss: 0.5613 - accuracy: 0.8074 - val_loss: 0.9112 - val_accuracy: 0.7081\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 3s - loss: 0.4321 - accuracy: 0.8510 - val_loss: 0.9907 - val_accuracy: 0.7094\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 3s - loss: 0.3061 - accuracy: 0.8962 - val_loss: 0.9520 - val_accuracy: 0.7193\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 3s - loss: 0.2078 - accuracy: 0.9311 - val_loss: 1.1135 - val_accuracy: 0.7129\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 3s - loss: 0.1415 - accuracy: 0.9548 - val_loss: 1.2856 - val_accuracy: 0.6978\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 3s - loss: 0.1008 - accuracy: 0.9688 - val_loss: 1.3512 - val_accuracy: 0.7174\n",
            "\n",
            "Epoch 1/100\n",
            " 85%|████████▌ | 34/40 [51:48<05:48, 58.02s/it, best loss: -0.7192999720573425]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0126s vs `on_train_batch_end` time: 0.0365s). Check your callbacks.\n",
            "196/196 - 10s - loss: 1.7239 - accuracy: 0.4217 - val_loss: 1.3741 - val_accuracy: 0.5116\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 10s - loss: 1.0666 - accuracy: 0.6320 - val_loss: 0.9815 - val_accuracy: 0.6606\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 10s - loss: 0.7582 - accuracy: 0.7401 - val_loss: 0.9488 - val_accuracy: 0.6750\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 10s - loss: 0.4872 - accuracy: 0.8366 - val_loss: 1.0018 - val_accuracy: 0.6861\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 10s - loss: 0.2581 - accuracy: 0.9162 - val_loss: 1.0930 - val_accuracy: 0.6964\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 10s - loss: 0.1201 - accuracy: 0.9636 - val_loss: 1.4515 - val_accuracy: 0.6564\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 10s - loss: 0.0701 - accuracy: 0.9800 - val_loss: 1.4238 - val_accuracy: 0.6919\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 10s - loss: 0.0486 - accuracy: 0.9875 - val_loss: 1.5623 - val_accuracy: 0.7182\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 10s - loss: 0.0461 - accuracy: 0.9886 - val_loss: 1.6886 - val_accuracy: 0.7201\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 10s - loss: 0.0402 - accuracy: 0.9902 - val_loss: 1.7125 - val_accuracy: 0.7161\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 10s - loss: 0.0209 - accuracy: 0.9937 - val_loss: 2.1983 - val_accuracy: 0.6835\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 10s - loss: 0.0294 - accuracy: 0.9920 - val_loss: 1.9984 - val_accuracy: 0.7157\n",
            "\n",
            "Epoch 1/100\n",
            "196/196 - 3s - loss: 1.8454 - accuracy: 0.3472 - val_loss: 1.4410 - val_accuracy: 0.4868\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 2s - loss: 1.3583 - accuracy: 0.5220 - val_loss: 1.2821 - val_accuracy: 0.5495\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 2s - loss: 1.1383 - accuracy: 0.6010 - val_loss: 1.1400 - val_accuracy: 0.5983\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 2s - loss: 0.9830 - accuracy: 0.6567 - val_loss: 0.9956 - val_accuracy: 0.6602\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 2s - loss: 0.8570 - accuracy: 0.7028 - val_loss: 1.0256 - val_accuracy: 0.6456\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 2s - loss: 0.7338 - accuracy: 0.7465 - val_loss: 1.0446 - val_accuracy: 0.6579\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 2s - loss: 0.6247 - accuracy: 0.7834 - val_loss: 0.9811 - val_accuracy: 0.6805\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 2s - loss: 0.5138 - accuracy: 0.8240 - val_loss: 0.9496 - val_accuracy: 0.6939\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 2s - loss: 0.4063 - accuracy: 0.8616 - val_loss: 1.0408 - val_accuracy: 0.6951\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 2s - loss: 0.3123 - accuracy: 0.8936 - val_loss: 1.2096 - val_accuracy: 0.6645\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 2s - loss: 0.2262 - accuracy: 0.9245 - val_loss: 1.0896 - val_accuracy: 0.7169\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 2s - loss: 0.1663 - accuracy: 0.9473 - val_loss: 1.4694 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 2s - loss: 0.1188 - accuracy: 0.9628 - val_loss: 1.5672 - val_accuracy: 0.6624\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 2s - loss: 0.1046 - accuracy: 0.9679 - val_loss: 1.3295 - val_accuracy: 0.7166\n",
            "\n",
            "Epoch 1/100\n",
            " 90%|█████████ | 36/40 [54:26<04:19, 64.90s/it, best loss: -0.7200999855995178]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0167s vs `on_train_batch_end` time: 0.0394s). Check your callbacks.\n",
            "196/196 - 12s - loss: 2.7061 - accuracy: 0.3970 - val_loss: 1.2973 - val_accuracy: 0.5454\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 12s - loss: 1.1101 - accuracy: 0.6130 - val_loss: 1.8765 - val_accuracy: 0.4196\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 12s - loss: 0.9043 - accuracy: 0.6882 - val_loss: 1.7554 - val_accuracy: 0.4866\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 12s - loss: 0.7365 - accuracy: 0.7472 - val_loss: 1.1403 - val_accuracy: 0.6258\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 12s - loss: 0.6002 - accuracy: 0.7950 - val_loss: 1.1163 - val_accuracy: 0.6614\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 12s - loss: 0.4601 - accuracy: 0.8417 - val_loss: 1.1407 - val_accuracy: 0.6706\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 12s - loss: 0.3593 - accuracy: 0.8757 - val_loss: 1.1884 - val_accuracy: 0.6798\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 12s - loss: 0.2850 - accuracy: 0.9050 - val_loss: 1.6593 - val_accuracy: 0.6394\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 12s - loss: 0.2184 - accuracy: 0.9270 - val_loss: 1.6484 - val_accuracy: 0.6543\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 12s - loss: 0.1951 - accuracy: 0.9395 - val_loss: 3.6817 - val_accuracy: 0.5031\n",
            "\n",
            "Epoch 1/100\n",
            "196/196 - 3s - loss: 1.8760 - accuracy: 0.3365 - val_loss: 1.7491 - val_accuracy: 0.4207\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 3s - loss: 1.3388 - accuracy: 0.5356 - val_loss: 1.2162 - val_accuracy: 0.5687\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 3s - loss: 1.1024 - accuracy: 0.6188 - val_loss: 1.1991 - val_accuracy: 0.5837\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 3s - loss: 0.9196 - accuracy: 0.6806 - val_loss: 1.1415 - val_accuracy: 0.6046\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 3s - loss: 0.7501 - accuracy: 0.7436 - val_loss: 1.0829 - val_accuracy: 0.6278\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 3s - loss: 0.5942 - accuracy: 0.7964 - val_loss: 1.0573 - val_accuracy: 0.6660\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 3s - loss: 0.4376 - accuracy: 0.8506 - val_loss: 1.0410 - val_accuracy: 0.6944\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 3s - loss: 0.3009 - accuracy: 0.8985 - val_loss: 1.2005 - val_accuracy: 0.6760\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 3s - loss: 0.2017 - accuracy: 0.9349 - val_loss: 1.2734 - val_accuracy: 0.6778\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 3s - loss: 0.1320 - accuracy: 0.9582 - val_loss: 1.4012 - val_accuracy: 0.6858\n",
            "\n",
            "Epoch 1/100\n",
            " 95%|█████████▌| 38/40 [56:53<02:10, 65.43s/it, best loss: -0.7200999855995178]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0134s vs `on_train_batch_end` time: 0.0389s). Check your callbacks.\n",
            "196/196 - 11s - loss: 1.8989 - accuracy: 0.3989 - val_loss: 1.2951 - val_accuracy: 0.5493\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 11s - loss: 1.1121 - accuracy: 0.6136 - val_loss: 1.1318 - val_accuracy: 0.5987\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 11s - loss: 0.7903 - accuracy: 0.7259 - val_loss: 1.1175 - val_accuracy: 0.6286\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 11s - loss: 0.5094 - accuracy: 0.8258 - val_loss: 0.9413 - val_accuracy: 0.7003\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 11s - loss: 0.2614 - accuracy: 0.9133 - val_loss: 1.2819 - val_accuracy: 0.6659\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 11s - loss: 0.1197 - accuracy: 0.9628 - val_loss: 1.3097 - val_accuracy: 0.7060\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 11s - loss: 0.0648 - accuracy: 0.9802 - val_loss: 1.4674 - val_accuracy: 0.7023\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 11s - loss: 0.0433 - accuracy: 0.9873 - val_loss: 1.6982 - val_accuracy: 0.7088\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 11s - loss: 0.0368 - accuracy: 0.9888 - val_loss: 2.0314 - val_accuracy: 0.6887\n",
            "\n",
            "Epoch 10/100\n",
            "196/196 - 11s - loss: 0.0361 - accuracy: 0.9897 - val_loss: 1.7800 - val_accuracy: 0.7151\n",
            "\n",
            "Epoch 11/100\n",
            "196/196 - 11s - loss: 0.0295 - accuracy: 0.9923 - val_loss: 1.9095 - val_accuracy: 0.7208\n",
            "\n",
            "Epoch 12/100\n",
            "196/196 - 11s - loss: 0.0282 - accuracy: 0.9926 - val_loss: 2.3108 - val_accuracy: 0.6815\n",
            "\n",
            "Epoch 13/100\n",
            "196/196 - 11s - loss: 0.0198 - accuracy: 0.9943 - val_loss: 2.4308 - val_accuracy: 0.6925\n",
            "\n",
            "Epoch 14/100\n",
            "196/196 - 11s - loss: 0.0263 - accuracy: 0.9940 - val_loss: 2.3599 - val_accuracy: 0.6991\n",
            "\n",
            "Epoch 1/100\n",
            " 98%|█████████▊| 39/40 [59:25<01:31, 91.34s/it, best loss: -0.72079998254776]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0196s vs `on_train_batch_end` time: 0.0598s). Check your callbacks.\n",
            "196/196 - 16s - loss: 8.1490 - accuracy: 0.2851 - val_loss: 1.8958 - val_accuracy: 0.3627\n",
            "\n",
            "Epoch 2/100\n",
            "196/196 - 16s - loss: 1.5938 - accuracy: 0.4728 - val_loss: 1.3764 - val_accuracy: 0.5161\n",
            "\n",
            "Epoch 3/100\n",
            "196/196 - 16s - loss: 1.2619 - accuracy: 0.5679 - val_loss: 1.7258 - val_accuracy: 0.4898\n",
            "\n",
            "Epoch 4/100\n",
            "196/196 - 16s - loss: 1.0578 - accuracy: 0.6338 - val_loss: 1.3853 - val_accuracy: 0.5340\n",
            "\n",
            "Epoch 5/100\n",
            "196/196 - 16s - loss: 0.9058 - accuracy: 0.6861 - val_loss: 1.2314 - val_accuracy: 0.5946\n",
            "\n",
            "Epoch 6/100\n",
            "196/196 - 16s - loss: 0.7734 - accuracy: 0.7343 - val_loss: 1.2077 - val_accuracy: 0.6093\n",
            "\n",
            "Epoch 7/100\n",
            "196/196 - 16s - loss: 0.6456 - accuracy: 0.7761 - val_loss: 1.5460 - val_accuracy: 0.5633\n",
            "\n",
            "Epoch 8/100\n",
            "196/196 - 16s - loss: 0.5211 - accuracy: 0.8195 - val_loss: 1.6309 - val_accuracy: 0.5760\n",
            "\n",
            "Epoch 9/100\n",
            "196/196 - 16s - loss: 0.4187 - accuracy: 0.8544 - val_loss: 1.7774 - val_accuracy: 0.5837\n",
            "\n",
            "100%|██████████| 40/40 [1:01:54<00:00, 92.86s/it, best loss: -0.72079998254776] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "PX9IOp4OCX_E",
        "outputId": "84e146df-1999-403f-8d69-9a6ce0f9e706"
      },
      "source": [
        "# print the parameters of the 5 best model\n",
        "import pandas\n",
        "hyperas_log = pandas.read_csv('hyperas-cifar10-log.csv', delimiter=';')\n",
        "hyperas_best5 = hyperas_log.sort_values(by=['best_val_acc'], ascending=False).head(n=5)\n",
        "hyperas_best5"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>layer1</th>\n",
              "      <th>kernel1</th>\n",
              "      <th>maxpooling1</th>\n",
              "      <th>layer2</th>\n",
              "      <th>kernel2</th>\n",
              "      <th>maxpooling2</th>\n",
              "      <th>layer3</th>\n",
              "      <th>act</th>\n",
              "      <th>optim</th>\n",
              "      <th>n_batch</th>\n",
              "      <th>best_val_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>128</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>2048</td>\n",
              "      <td>relu</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>256</td>\n",
              "      <td>0.7208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>128</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>2048</td>\n",
              "      <td>relu</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>256</td>\n",
              "      <td>0.7201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>64</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>128</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>2048</td>\n",
              "      <td>relu</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>256</td>\n",
              "      <td>0.7193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>128</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>2048</td>\n",
              "      <td>relu</td>\n",
              "      <td>rmsprop</td>\n",
              "      <td>128</td>\n",
              "      <td>0.7174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>64</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>128</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>1024</td>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>256</td>\n",
              "      <td>0.7172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    layer1  kernel1  maxpooling1  layer2  ...   act    optim  n_batch best_val_acc\n",
              "38      32        3        False     128  ...  relu  rmsprop      256       0.7208\n",
              "34      16        3        False     128  ...  relu  rmsprop      256       0.7201\n",
              "33      64        3         True     128  ...  relu  rmsprop      256       0.7193\n",
              "13      16        3        False     128  ...  relu  rmsprop      128       0.7174\n",
              "10      64        5         True     128  ...  relu     adam      256       0.7172\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zskGqWmYCrNY",
        "outputId": "70fa9aff-96e4-465b-d581-a6ab549285d6"
      },
      "source": [
        "# visualize the results\n",
        "import matplotlib.pyplot as plt\n",
        "for hyperparam in ['layer1', 'kernel1', 'layer2', 'kernel2', 'layer3', 'n_batch']:\n",
        "  ax1 = hyperas_log.plot(kind='scatter', x=hyperparam, y='best_val_acc')\n",
        "  hyperas_best5.plot(kind='scatter', x=hyperparam, y='best_val_acc', color='red', ax=ax1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAakklEQVR4nO3dfXBd9X3n8fdHD5YFAluWBCWWg01sbwKJbYKWhLjTJelAnAlrMgW8NO0O9IndmbCBJYXAzubJbB7KLk3TDdsJS2ih0y5xoAmmk67LEJJsHshaDsbUJhjHPFjeJhhZDghsWQ/f/eMcwZWii3XNPfeeq/N5zWik8zvn6H6PdX2+9/dwfj9FBGZmZjNpqncAZmaWX04SZmZWlpOEmZmV5SRhZmZlOUmYmVlZLfUOoJq6u7tj6dKl9Q7DzKyhbNu27YWI6Jlp35xKEkuXLqW/v7/eYZiZNRRJz5bb5+YmMzMry0nCzMzKcpIwM7OynCTMzKwsJwkzMyvLScJy6+DTA+z++29z8OmBeodiVlhOEinfkPJl6+dvo33lck679F/TvnI5/V+4rd4hmeVWlvcvJwl8Q8qbg08P8PZPfoz2sRFOGnmF9rERzvrEx5zAzWaQ9f2r8EnCN6T8eWHnbsaam6eUjTU388LO3XWKyCyfanH/KnySeGHnboiJqYUx4RtSHXWftZKW8fEpZS3j43SftbJOEZnl0ws7dxMZ378KnyTmLTiZ+eOjU8rmj48yb8HJdYrIFi3rZefNt3K4pY2X2k7gcEsbO2++lUXLeusdmlmujLS10z7D/Wukrb1qrzGn5m46Hkd/+SJHWubRPnb01bIjLfM4+ssX6xiV9d34EQ7+m4t5Yeduus9aSZ8ThNmveObZX7B8hvvXM8/+gndU6TUKnyTKNWG4aaP+Fi3rde3B7HWM9r65ovLjUfjmpujp4aYPXsvhlnm8OO8EDrfM46YPXkv0zDhrrplZbnSf0cv1H7hmyv3r+g9cQ/cZ1ftwVfiaxMDQYR5a/T7Wvnk1vb/8BQMLTmW0s4vfGzpMV0dbvcMzMyvrrDctYMs7zueHS9e8ev966aSFfOZNC6r2GoVPEr2d7bwyOs74CQs4eELyD9s8Ok5vZ/U6fszMstDV0catl63m+nt3sGfhIsYnglsvXVXVD7iFTxJDLx9lfCKmlI1PBEMvH3VNwsxyb/2axaxd3s3A0GF6O9urft8qfJL4/p4XypYvP/WkGkdjZla5ro62zD7UFr7jurvMP2y5cjOzIil8kjjvLV00N2lKWXOTOO8tXXWKyCYNDo/w2L5DDA6P1DsUs8IqfHNTV0cbX9ywmj/++g4gAPHfLqtux49V7v7t+/n4fTtobWpidGKCWy5Zxfo1i+sdllnhFL4mAWlqUNDS1IQUxzzesjU4PMLH79vBkdEJXhoZ48joBDfct8M1CrM6yDxJSFon6UlJeyTdOMP+L0rann7tlnSoZN8Vkp5Kv67IIr7JG9LIWPDK6DgjY+EbUp0NDB2mtWnqW7O1qYmBocN1isisuDJtbpLUDNwGXAAMAFslbY6IXZPHRMR/LDn+PwBnpz8vAj4F9JF82N+WnjtUzRgnb0hHeG0mxckbkpuc6qO3s53RiakzW45OTPjZFbM6yLomcS6wJyL2RsRR4B7g4tc5/reB/5X+/H7gwYg4mCaGB4F11Q7QN6T86epo45ZLVjG/tYmT2lqY39rELZe4n8isHrLuuF4M7CvZHgDeNdOBkk4HlgHffp1zf6XnUtJVwFUAb35z5ZNadXW0seGcXu5+5LlXyzb09fqGVGfr1yzmzNNOZvu+Q6xZstDPrJjVSZ46ri8H7o2I8WMeWSIibo+Ivojo6zmOSfkGh0fYtG3qKk6b+gfcJ1Fn92/fz0Vf/j6feWAXF335+2zevr/eIZnlVpbDxbOuSewHlpRs96ZlM7kc+Mi0c8+fdu53qhgb4D6JPCod3TT5d7nhvh2sXd7tv4nZNPdv388N9z5Gs5oYjwn+66WrqzpcPOuaxFZghaRlkuaRJILN0w+S9FagE/hRSfEW4EJJnZI6gQvTsqpyn0T+eHST2ewMDo/wsU3bp4zOvG7T9qrWKDJNEhExBlxNcnN/AtgUETslbZS0vuTQy4F7IiJKzj0I3EySaLYCG9OyqnInaf44cZvNzs7/9yJj05a4HptIyqsl8yeuI+JbwLemlX1y2vany5x7J3BnZsGlsp5F0SozmbhvmPbEtf8uZtOVe/i3eg8FF35ajklZzqJolXPiNju2s960gNZmMTr+WlJobRZnVXHRoTyNbjKboqujjdVLFjpBmJUxuehQW0sTJ8xrpq2liVsvW+1Fh8zMLOFFh8zM7HV50SEzM6sLJ4mUF7gxM/tVbm7CC9yYWWMbHB5xn0RWPAWEmTWyrD/kFr65yVNAmFmjqsUqjoVPEr2d7RweHZtSdnh0zFNAmFnu1eJDbuGTBICk1902M8ujWsxzVvgkMTB0mPktzVPK5rc0u7nJzHKvFhOUFr7j2jOOmlkjy/qJ68LXJDxVuJk1uiznOSt8TQI846iZNTY/J1EDnirczBqRn5MwM7MZ+TkJMzMry89JWKF50kWz11eL0Znuk7Bc8qSLZsfW1dHGhr5e7v7Rc6+WbejrrWr/qmsSlju1aGc1mwsGh0fY1D8wpWxT/4D7JGxu86SLZrPjPgkrJE+6aDY7nrvJCsuTLpodm+duskKanHRxdPy12sTkpIt+4NFsqqxnjHCSSGX5WLtVxpMumlUmyxkjnCTwcMu8qcWwPjObncL3SXi4Zf7UYlifmc1O4ZOEh1vmj/8mZvlR+CTh9u/88d/ELD8KnyS86FD++G9ilh+KiHrHUDV9fX3R399/XOd6dFP++G9iVhuStkVE30z7Mq9JSFon6UlJeyTdWOaYDZJ2Sdop6W9LysclbU+/NmcZZ5bL/9nx8d/ErP4yHQIrqRm4DbgAGAC2StocEbtKjlkB3ASsjYghSaeU/IrDEbEmyxjNzKy8rGsS5wJ7ImJvRBwF7gEunnbMHwG3RcQQQEQ8n3FMZmY2S1knicXAvpLtgbSs1EpgpaQfSHpE0rqSffMl9aflH5rpBSRdlR7Tf+DAgepGb2ZWcHl44roFWAGcD/QC35P0jog4BJweEfslnQF8W9LjEfGz0pMj4nbgdkg6rmsbuplZ/WU5yCPrJLEfWFKy3ZuWlRoAfhwRo8DTknaTJI2tEbEfICL2SvoOcDbwM8zMDMh+WqGsm5u2AiskLZM0D7gcmD5K6ZsktQgkdZM0P+2V1CmpraR8LbALMzMDajOtUKZJIiLGgKuBLcATwKaI2Clpo6T16WFbgEFJu4CHgesjYhB4G9Av6bG0/Aulo6LMzIqu3FQ11ZzCJvM+iYj4FvCtaWWfLPk5gOvSr9Jjfgi8I+v4zMwa1YnzmjkyOnUKmyOjE5w4r7lqr1H4aTkmDQ6P8Ni+Q55p1MwaxstHx2lrnrpqY1uzePnoeNVeIw+jm+rO60mYWSPq7WxHTYLx1wZ2qkle47qavJ6EmTUqr3FdA5NrFxzhtXa9ybULPGdQfXmCP7Nj8xrXGfPaBfnkJkCz2ctyjevCNzd1dbSx4ZzeKWVeT7m+3ARolh+FTxKDwyNs2ub1lPPEy5ea5cesk4SkuyQtLNnulHRnNmHVjm9I+eMmQLP8qKQmsSqddA+AdGrvs6sfUm31drZzZGzqmOIjY+O+IdWRly81y49KOq6bJHVOrvsgaVGF5+fW9CVc59KSro0q6xEbZjY7ldzkbwV+JOnr6fZlwGerH1JtDQwdpr21hZdGxl4ta29t8RDYHMhyxIaZzc6sk0RE3C2pH3hfWvRbc2HCPbd/m5mVV0nH9buBfRHx5Yj4MjAg6V3ZhVYbbv82MyuvkuamvwDeWbI9PENZQ3L7t5nZzCpJEoqSHt2ImJA0Jzquwe3fZmYzqWQI7F5JH5XUmn5dA+zNKjAzM6u/SpLEvwfeQ7JG9QDwLuCqLIIyM7N8qGR00/Mka1SbmVlBzDpJSJoP/AFwFjB/sjwifj+DuMzMLAcqaW76a+DXgPcD3wV6gZeyCMrMzPKhkiSxPCI+AbwcEXcBHyTplzAzszoaHB7hsX2HMpm9upIhrKPp90OS3g78HDil6hGZmdmsZb1AVyU1idsldQL/GdgM7AL+pGqRmJlZRWqxQFclo5vuSH/8HnDG9P2SrkiboczMrAYm18M5wmvzz02uh1Oth4OruTLdNVX8XWaZtrOazQW1mKC0mtNqqIq/ywou63ZWs7lgcoLSG6b9X6nmFEPVTBJeqceqorSddbIafcN9O1i7vNvza5lNk/UEpa5JWO7Uop3VbC7JcoLSavZJ/KCKv8sKzAtBmeXHMWsSkq57vf0R8afp96urFZQVWy3aWc1sdmbT3HRS5lGYTeOFoMzy4ZhJIiI+80ZeQNI64EtAM3BHRHxhhmM2AJ8m6fx+LCI+nJZfQfLwHsB/8XMYxeKFoMzqL9NZYCU1A7cBF5CsQbFV0uaI2FVyzArgJmBtRAxJOiUtXwR8CugjSR7b0nOHKrg+MzN7A7KeBfZcYE9E7I2Io8A9wMXTjvkj4LbJm3+6bgXp6zwYEQfTfQ8C6yqI18zM3qCsZ4FdDOwr2R5Iy0qtBFZK+oGkR9Lmqdmei6SrJPVL6j9w4EAFl2NmZsdSSZKYPgvsAqozC2wLsAI4H/ht4H9KWjjbkyPi9ojoi4i+np6eKoRjZmaTjmcW2E8w+1lg9wNLSrZ707JSA8DmiBiNiKeB3SRJYzbnmplZhipJEn8ZEUMR8d2IOCMiTomIrxzjnK3ACknLJM0jWSN787RjvklSi0BSN0nz015gC3ChpM40OV2YlpmZWY1UkiSelnS7pN+UNKspOCJiDLia5Ob+BLApInZK2ihpfXrYFmBQ0i7gYeD6iBiMiIPAzSSJZiuwMS0zM7MaUcTs5uWTdAJwEUlt4BzgAeCeiPh+duFVpq+vL/r7++sdhplZQ5G0LSL6Zto365pERLwSEZsi4reANcDJJENhzcxsjqpogj9J/0rS/wC2kTxQtyGTqMzMLBcqeeL6GeBRYBNJv8HLWQVlZmb5UMl6Eqsi4sVyOyXdFBGfr0JMZmaWE5X0SZRNEKnL3mAsZmaWM9VcdMgr05mZzTHVTBJe49rMbI5xTcLMzMqadZKQtPYYZV+vSkRmZpYbldQk/vvrlUXE5954OGZmlifHHAIr6TzgPUCPpOtKdp1MsiSpmZnNUbN5TmIe0JEee1JJ+YvApVkEZWZm+XDMJBER3wW+K+mvIuJZAElNQMcsnp0wM7MGVkmfxOclnSzpROCfgF2Srs8oLjMzy4FKksSZac3hQ8A/AMuAf5tJVGZmlguVJIlWSa0kSWJzRIziB+jMzOa0SpLEV4BngBOB70k6naTz2szM5qhZzwIbEX8O/HlJ0bOS3lv9kMzMLC8qeeL6VElflfQP6faZwBWZRWZmZnVXSXPTXwFbgDel27uBa6sdkJmZ5UclSaI7IjYBEwARMQaMZxKVmZnlQiVJ4mVJXaQjmiS9G/hlJlGZmVkuVLJ86XXAZuAMST8AevC0HGZmc1olSWIX8A3gFeAl4Jsk/RJmZjZHVdLcdDfwVuBzJFOErwT+OougzMwsHyqpSbw9Is4s2X5Y0q5qB2RmZvlRSU3iJ2lnNQCS3gX0Vz8kMzPLi9ksOvQ4yYimVuCHkp5Lt08HfppteGZmVk+zaW66KPMozMwsl2az6NCztQjEzMzyp5I+CTMzKxgnCTMzKyvzJCFpnaQnJe2RdOMM+6+UdEDS9vTrD0v2jZeUb846VjMzm6qS5yQqJqkZuA24ABgAtkraHBHTn6/4WkRcPcOvOBwRa7KM0czMysu6JnEusCci9kbEUeAe4OKMX9PMzKok6ySxGNhXsj2Qlk13iaQdku6VtKSkfL6kfkmPSPrQTC8g6ar0mP4DBw5UMXQzM8tDx/UDwNKIWAU8CNxVsu/0iOgDPgz8maS3TD85Im6PiL6I6Ovp6alNxGZmBZF1ktgPlNYMetOyV0XEYESMpJt3AOeU7Nufft8LfAc4O8tgzcxsqqyTxFZghaRlkuYBl5OsSfEqSaeVbK4HnkjLOyW1pT93A2tJpis3M7MayXR0U0SMSbqaZG3sZuDOiNgpaSPQHxGbgY9KWg+MAQeBK9PT3wZ8RdIESTL7wgyjoszMLEOKiHrHUDV9fX3R3++Jac3MKiFpW9r/+yvy0HFtZmY55SRhZmZlOUmYmVlZThJmZlaWk4SZmZXlJGFmZmU5SZiZWVlOEmZmVpaThJmZleUkYWZmZTlJmJlZWU4SZmZWlpOEmZmV5SRhZmZlOUmYmVlZThJmZlaWk4SZmZXlJGFmZmU5SZiZWVlOEmZmVpaThJlZgxscHuGxfYcYHB6p+u9uqfpvNDOzmrl/+34+ft8OWpuaGJ2Y4JZLVrF+zeKq/X7XJMzMGtTg8Agfv28HR0YneGlkjCOjE9xw346q1iicJCy3sqxCm80FA0OHaW2aehtvbWpiYOhw1V7DzU2WS1lXoc3mgt7OdkYnJqaUjU5M0NvZXrXXcE3CcqcWVWizuaCro40Nfb1Tyjb09dLV0Va113CSsNypRRXabC4YHB5hU//AlLJN/QPuk7C5rRZVaLO5oBYfqJwkLHe6Otq45ZJVzG9t4qS2Fua3NnHLJauqWoU2mwtq8YHKHdeWS+vXLGbt8m4Ghg7T29nuBGE2g8kPVDdMG+RRzf8vThKWW10dbU4OZseQ9QeqzJubJK2T9KSkPZJunGH/lZIOSNqefv1hyb4rJD2Vfl2RdaxmZo2oq6ON1UsWZvKhKtOahKRm4DbgAmAA2Cppc0Tsmnbo1yLi6mnnLgI+BfQBAWxLzx3KMmYzM3tN1jWJc4E9EbE3Io4C9wAXz/Lc9wMPRsTBNDE8CKzLKE4zM5tB1kliMbCvZHsgLZvuEkk7JN0raUkl50q6SlK/pP4DBw5UK24zMyMfQ2AfAJZGxCqS2sJdlZwcEbdHRF9E9PX09GQSoJlZUWWdJPYDS0q2e9OyV0XEYERMPh54B3DObM81M7NsZZ0ktgIrJC2TNA+4HNhceoCk00o21wNPpD9vAS6U1CmpE7gwLTMzsxrJdHRTRIxJuprk5t4M3BkROyVtBPojYjPwUUnrgTHgIHBleu5BSTeTJBqAjRFxMMt4zcxsKkVEvWOomr6+vujv7693GGZmDUXStojom2lfHjquzcwsp5wkzMysLCcJMzMry0nCzKzBZbkevGeBNTNrYFmvB++ahJlZg6rFevBOEmZmDcrLl5qZWVm1WL7UScLMrEHVYj14d1ybmTWwrJcvdZJIDQ6PZPaPbGaWpSzXg3eSIPshZGZmjarwfRK1GEJmZtaoCp8kajGEzMysURU+SdRiCJmZWaMqfJKoxRAyM7NG5Y5rsh9CZmbWqJwkUlkOITMza1SFb24yM7PynCTMzKwsJwkzMyvLScLMzMpykjAzs7IUEfWOoWokHQCerXccx9ANvFDvIOqkyNcOxb7+Il875P/6T4+Inpl2zKkk0Qgk9UdEX73jqIciXzsU+/qLfO3Q2Nfv5iYzMyvLScLMzMpykqi92+sdQB0V+dqh2Ndf5GuHBr5+90mYmVlZrkmYmVlZThJmZlaWk0RGJC2R9LCkXZJ2SromLV8k6UFJT6XfO+sdaxYkzZf0fyU9ll7/Z9LyZZJ+LGmPpK9JmlfvWLMiqVnSo5L+Pt0u0rU/I+lxSdsl9adlRXnvL5R0r6SfSnpC0nmNfO1OEtkZAz4WEWcC7wY+IulM4EbgoYhYATyUbs9FI8D7ImI1sAZYJ+ndwJ8AX4yI5cAQ8Ad1jDFr1wBPlGwX6doB3hsRa0qeDyjKe/9LwP+OiLcCq0neAw177U4SGYmIf46In6Q/v0TyRlkMXAzclR52F/Ch+kSYrUgMp5ut6VcA7wPuTcvn7PVL6gU+CNyRbouCXPvrmPPvfUkLgN8AvgoQEUcj4hANfO1OEjUgaSlwNvBj4NSI+Od018+BU+sUVubS5pbtwPPAg8DPgEMRMZYeMkCSOOeiPwNuACYXUO+iONcOyQeCf5S0TdJVaVkR3vvLgAPAX6ZNjXdIOpEGvnYniYxJ6gDuA66NiBdL90Uy/njOjkGOiPGIWAP0AucCb61zSDUh6SLg+YjYVu9Y6ujXI+KdwAdImlp/o3TnHH7vtwDvBP4iIs4GXmZa01KjXbuTRIYktZIkiL+JiL9Li38h6bR0/2kkn7LntLS6/TBwHrBQ0uSyub3A/roFlp21wHpJzwD3kDQzfYliXDsAEbE//f488A2SDwlFeO8PAAMR8eN0+16SpNGw1+4kkZG0DfqrwBMR8acluzYDV6Q/XwHcX+vYakFSj6SF6c/twAUk/TIPA5emh83J64+ImyKiNyKWApcD346I36EA1w4g6URJJ03+DFwI/BMFeO9HxM+BfZL+RVr0m8AuGvja/cR1RiT9OvB/gMd5rV36P5H0S2wC3kwyrfmGiDhYlyAzJGkVSQddM8mHkU0RsVHSGSSfrhcBjwK/GxEj9Ys0W5LOB/44Ii4qyrWn1/mNdLMF+NuI+KykLorx3l9DMmBhHrAX+D3S/wM04LU7SZiZWVlubjIzs7KcJMzMrCwnCTMzK8tJwszMynKSMDOzspwkzCogafjYR73h1/ispH21eC2zY3GSMMsJJZqAB0ieUDarOycJs+MgqUPSQ5J+kq6bcHFavlHStSXHfbZkLZHrJW2VtKNkfY2lkp6UdDfJU8lLIuKRksngzOrKD9OZVUDScER0pHMwnRARL0rqBh4BVgCnA38XEe9MawVPkdQKziGZkuPfASKZpuEW4DmSp3LfExGPzPRatbo2s5m0HPsQM5uBgM+ls5tOkEz7fWpEPCNpUNLZJNNBPxoRg5IuJJnD6NH0/A6SpPIc8Oz0BGGWF04SZsfnd4Ae4JyIGE1nfJ2f7rsDuBL4NeDOtEzA5yPiK6W/JF1r5OXswzU7Pu6TMDs+C0jWjBiV9F6SZqZJ3wDWAf8S2JKWbQF+P11fBEmLJZ1Sy4DNjodrEmbH52+AByQ9DvQDP53cERFHJT1MshLdeFr2j5LeBvwomUWeYeB3gfHpv1jSLcCHgRMkDQB3RMSnM74esxm549qsytIO658Al0XEU/WOx+yNcHOTWRVJOhPYAzzkBGFzgWsSZmZWlmsSZmZWlpOEmZmV5SRhZmZlOUmYmVlZThJmZlbW/wcKaygPB9inlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEHCAYAAABbZ7oVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbH0lEQVR4nO3df5RcZZ3n8fenO51OoEPSdCJCOpAAyboQQ9A64Jpxx/kBZlCDawTRPTNwZkbOnF1WNLsGOLOigzOieJjdcSc7Gh0UPKMQyY7GOboMuyCcQWDT0RBIEAjhRzqjmOk0hkDS6U5/94+6Taqbvt1Vyb1Vt7s/r3OKVD333qovVbfrW8+P+zyKCMzMzEbT1OgAzMysuJwkzMwslZOEmZmlcpIwM7NUThJmZpZqWqMDyNLcuXNj4cKFjQ7DzGxC2bJly79ExLzRtk2qJLFw4UK6uroaHYaZ2YQi6YW0bW5uMjOzVE4SZmaWyknCzMxSOUmYmVkqJwkzM0vlJGFmNsHte66bp//hPvY91535cztJmJlNYJtvXsfMxWcx/4OXMHPxWXR9YV2mz6/JNFV4qVQKXydhZlPFvue6aTtrIdPjyOtlh9XMgWef5+RFnVU/j6QtEVEabZtrElZYeVahzSaD7vseoqUiQQC0xBG673sos9dwkrBC2nzzOmYuOYtTP/R+Zi7JvgptNhkc7umtqfxYOElY4ex7rpulN65h5sBhZvW9xsyBw5z76TWuUZg1gJOEFc7zW3bQ3zR8WrH+pmk8v2VHgyIyK6aBWbNrKj8WThJWOH2dnbQMDgwraxkcoK+z+o44s6lg/1uWjvqDav9blmb2Gk4SVjhLlp7FdZdcy8Fp09k//QQOTpvOdZdcy5KlZzU6NLNCmTH/zax57yc5NG06r7bM4NC06ax57yeZMf/Nmb3GpJoq3CaPHy19N/90xnI6f/0S3bNP4ZVZc/hMo4MyK5hzTzuJ/730N/nJwqN/K/vbZvNnp52U2Ws4SVjhdPcepLlJ7DthNvtOKLetzmgS3b0H6WhrbXB0ZsXR0dbKRy88nTsefvH1v5U/uPD0TP9O3NxkhXPi9GYO9Q8OKzvUP8iJ05sbFJFZMfUc6OPbj744rOzbj75Iz4G+zF7DScIK59XDR2ht1rCy1mbx6uEjKUeYTU3b/3k/A8N/TzEwWC7PipOEFU5n+0zUNDxJqEl0ts9sUERmRZU2rVJ20y05SSR6DvTx2O6XM62m2bHpaGvlltXLmNHSxKzWacxoaeKW1cvcH2E2wrmnzaZlRK27pVmce1p210m44xr4/tY9XLdxGy1NTfQPDnLL6mWsWj6/0WFNaauWz2fF2XPp7j1IZ/tMJwizUXS0tXLrZefxqbu3vV72pQ9l+4Nqytckeg70cd3GbRzqH+SVvgEO9Q+yduM21ygKoKOtlfMWzHGCMBtDJP9tlsiymWlI7klC0kpJT0naKen6Ubb/N0lbk9vTkl6u2HalpGeS25V5xNfde5CWpuFvQ0tTE929B/N4OTOzzAz9yO0bCF7rP0LfQGT+IzfX5iZJzcA64CKgG9gsaVNEvD4JT0R8smL//wScn9w/GfgMUKKcHrckx2Y3vSHlTtL+weHDA/oHB91JamaFN/Qj9xBHv8OGfuRmVQPPuyZxAbAzInZFxGHgTuDSMfb/CPCd5P57gHsjYl+SGO4FVmYdoDtJi8uDCczGVo8fuXl3XM8Hdlc87gYuHG1HSWcAi4D7xjj2Db3Jkq4GrgY4/fTTjynIVcvnc86pJ7F198ssXzCHs0+ZdUzPY9nxYAKz8Q39yF074m8lyx+5RRrddAVwd0TUdMVURKwH1kN5+dJjeWF/IRVL5WCCoWr02o3bWHH2XNfwzEbIeyRg3s1Ne4AFFY87k7LRXMHRpqZajz1mHt1UPB5MYFYcedckNgOLJS2i/AV/BfDRkTtJegvQDjxcUXwP8HlJ7cnji4Ebsg6wu/cgMTi8AhKD4cnkGsiDCcyql3dLSK41iYgYAK6h/IX/JLAhIrZLuknSqopdrwDujIioOHYf8DnKiWYzcFNSlqkTpzfTd2R4kug7Ep5MroE8mMCsOvVoCcm9TyIifgj8cETZjSMefzbl2NuA23ILjvJkcjNamobNOjqjpcmTyTWYr7g2G189hsAWqeO6IdKaMNy00Xgdba1ODmZjqEfT7JSflsNNG2Y2UdXj+0sV3QATXqlUiq6urmM6tudAn5s2zGxCOt7vL0lbIqI02rYp39w0xE0bZjZR5fn9NeWbm8zMLJ2ThBWW524yazw3N1khfX/rHtbe/RjNauJIDPKlD53nqVLMGsA1CSucngN9/OcNW4fNkb9mw1bXKMwawEnCCmf7P+9nYPjQbwYGy+Vm9kZ5Ns26uckKKG1Y9uQZrm2WlQk9d5PZsTj3tNm0NGtYWUuzOPe02Q2KyKyY6jF3k5OEFU5HWyu3XnYerdOaOGF6M63Tmrj1svN8HYvZCPWYVt/NTVZInuDPbHyeu8mmtI62Vs5bMMcJwixFPeZuck3CzGwCW7V8PuecehJbd7/M8gVzOPuUWZk+v5OEmdkE5tFNZmY2Ko9uMjOzVPUY3eQkkfBkcmY20dRjdJP7JMi/Tc/MLA8dba1cXurkjodffL3s8lJnpqObpnxNoh5temZmeeg50MeGru5hZRu6ut0nkaV6tOmZmeXBfRJ1UI82PTOzPHS2z+Rg/8CwsoP9A77iOkv1uGLRzCwvksZ8fLzccY3nCTKziam79yAzpjXTf+RobWLGtGa6ew9m9j3mJJHoaGt1ciiYngN9TtxmY/AQWJuyPCzZbHweAmtTkoclm1XHQ2BtSvKwZLPqeAisTUkelmxWHS86ZFOShyWbVacefyuKiMyerNFKpVJ0dXU1OgzLiEc3mVXneP9WJG2JiNJo23KvSUhaKekpSTslXZ+yz+WSdkjaLunbFeVHJG1NbpvyjtWKxcuXmlUnz7+VXIfASmoG1gEXAd3AZkmbImJHxT6LgRuAFRHRK+lNFU9xMCKW5xmjmZmly7smcQGwMyJ2RcRh4E7g0hH7fAxYFxG9ABHxq5xjMjOzKuWdJOYDuysedydllZYASyQ9JOkRSSsrts2Q1JWUf2C0F5B0dbJP1969e7ON3sxsiivCFdfTgMXAu4FO4EFJb42Il4EzImKPpDOB+yQ9HhHPVh4cEeuB9VDuuK5v6GZmjZfnII+8k8QeYEHF486krFI38GhE9APPSXqactLYHBF7ACJil6QfA+cDz2JmZkD+U9jk3dy0GVgsaZGk6cAVwMhRSt+jXItA0lzKzU+7JLVLaq0oXwHswKYMrztuNrZ6TGGTa00iIgYkXQPcAzQDt0XEdkk3AV0RsSnZdrGkHcAR4FMR0SPpncBXJQ1STmZfqBwVZZObJ/gzG9/QtByHOHrV9dC0HBNmqvCI+CHwwxFlN1bcD2BNcqvc5yfAW/OOz4qn8tfR0Mm/duM2Vpw919dMmFXwtBw2JXmCP7Pq1GNajiKMbjIbprN9JocGjgwrOzRwxBP8mY0i75U1nSSskEbOKTaZ5hgzy1qeK2u6uckKp7v3IDNbhv9+mdkyzc1NZinyHAnomoQVjteTMKveRL9OwqxmHW2tXP72zmFlWa/bazYZ1OM6CScJK5yeA31s2JLvur1mk0Ghli+VdLukORWP2yXdllkkZgkPgTWrTtGuk1iWTLoHQDK19/mZRWKW8BBYs+oU7TqJJkntQ+s+SDq5xuPNquYhsGbVKdJ1ErcCD0v6bvL4MuAvMo3GjKNDYF/pG3i9bGgIrDuvzd4oz+skqk4SEXGHpC7gt5OiD3rCPcuDh8CaFUctHdfvAHZHxF9HxF8D3ZIuzC80m6rq0c5qZtWppbnpb4C3VTw+MEqZWSbybmc1s+rUkiQUFb2HETEoyR3Xlps821nNrDq1DIHdJenjklqS27XArrwCMzOzxqslSfwJ8E7Ka1R3AxcCV+cRlJmZFUMto5t+RXmNajMzmyKqThKSZgB/BJwLzBgqj4g/zCEuMzMrgFqam74FvBl4D/AA0Am8kkdQZmZWDLUkibMj4tPAqxFxO/Beyv0SZrnIcyEVM6tOLUNY+5N/X5a0FPgl8KbsQzLLfyEVM6tOLTWJ9ZLagf8KbAJ2AF/MJSqb0uqxkIqZVaeW0U1fT+4+CJw5crukK5NmKLPjMrSexCGOzt80tJ6EL64zq68sV6a7NsPnsinME/yZ1SbP/rssp9VQhs9lU9jQBH9rR/RJuBZh9kZ5999lmSS8KoxlxhP8mY2vsv9uqHl27cZtrDh7bmZ/M65JWGF5gj+zsdWj/y7LPomHMnwuMzMbRz3678atSUhaM9b2iPjL5N9rsgrKzMzGV4/+u2qam2Zl9mpmZpapvPvvxk0SEfFnx/MCklYCfwU0A1+PiC+Mss/lwGcpd34/FhEfTcqvpHzxHsCf+zoMM7M3yrP/LtdZYCU1A+uAiyivQbFZ0qaI2FGxz2LgBmBFRPRKelNSfjLwGaBEOXlsSY7treH/z8zMjkPes8BeAOyMiF0RcRi4E7h0xD4fA9YNffkn61aQvM69EbEv2XYvsLKGeM3M7DjlPQvsfGB3xePupKzSEmCJpIckPZI0T1V7LJKultQlqWvv3r01/O+Ymdl4akkSI2eBnU02s8BOAxYD7wY+AnxN0pxqD46I9RFRiojSvHnzMgjHzMyGHMsssJ+m+llg9wALKh53JmWVuoFNEdEfEc8BT1NOGtUca2ZmOaolSXwjInoj4oGIODMi3hQRXx3nmM3AYkmLJE2nvEb2phH7fI9yLQJJcyk3P+0C7gEultSeJKeLkzIzM6uTWpLEc5LWS/odSVVNwRERA8A1lL/cnwQ2RMR2STdJWpXsdg/QI2kHcD/wqYjoiYh9wOcoJ5rNwE1JmZmZ1YkiqpuXT9IJwPso1wbeDvwAuDMi/im/8GpTKpWiq6ur0WGYmU0okrZERGm0bVXXJCLitYjYEBEfBJYDJ1EeCmtmZpNUTRP8SfpNSf8T2EL5grrLc4nKzMwKoZYrrp8HfgZsoNxv8GpeQZmZWTHUsp7EsojYn7ZR0g0RcXMGMZmZWUHU0ieRmiASlx1nLGZmVjBZLjrklenMzCaZLJOE17g2M5tkXJMwM7NUVScJSSvGKftuJhGZmVlh1FKT+B9jlUXE548/HDMzK5Jxh8BK+jfAO4F5ktZUbDqJ8pKkZmY2SVVzncR0oC3Zd1ZF+X7gQ3kEZWZmxTBukoiIB4AHJH0zIl4AkNQEtFVx7YSZmU1gtfRJ3CzpJEknAk8AOyR9Kqe4zMysAGpJEuckNYcPAD8CFgG/n0tUZmZWCLUkiRZJLZSTxKaI6McX0JmZTWq1JImvAs8DJwIPSjqDcue1mZlNUlXPAhsRXwa+XFH0gqTfyj4kMzMrilquuD5F0t9K+lHy+BzgytwiMzOzhquluembwD3Aacnjp4FPZB2QmZkVRy1JYm5EbAAGASJiADiSS1RmZlYItSSJVyV1kIxokvQO4Ne5RGVmZoVQy/Kla4BNwJmSHgLm4Wk5zMwmtVqSxA7g74HXgFeA71HulzAzs0mqluamO4C3AJ+nPEX4EuBbeQRlZmbFUEtNYmlEnFPx+H5JO7IOyMzMiqOWmsRPk85qACRdCHRlH5KZmRVFNYsOPU55RFML8BNJLyaPzwB+nm94ZmbWSNU0N70v9yjMzKyQqll06IV6BGJmZsVTS5+EmZlNMU4SZmaWKvckIWmlpKck7ZR0/Sjbr5K0V9LW5PbHFduOVJRvyjtWMzMbrpbrJGomqRlYB1wEdAObJW2KiJHXV9wVEdeM8hQHI2J5njGamVm6vGsSFwA7I2JXRBwG7gQuzfk1zcwsI3knifnA7orH3UnZSKslbZN0t6QFFeUzJHVJekTSB0Z7AUlXJ/t07d27N8PQzcysCB3XPwAWRsQy4F7g9optZ0RECfgo8N8lnTXy4IhYHxGliCjNmzevPhGbmU0ReSeJPUBlzaAzKXtdRPRERF/y8OvA2yu27Un+3QX8GDg/z2DNzGy4vJPEZmCxpEWSpgNXUF6T4nWSTq14uAp4Milvl9Sa3J8LrKA8XbmZmdVJrqObImJA0jWU18ZuBm6LiO2SbgK6ImIT8HFJq4ABYB9wVXL4vwa+KmmQcjL7wiijoszMLEeKiEbHkJlSqRRdXZ6Y1sysFpK2JP2/b1CEjmszMysoJwkzM0vlJGFmZqmcJMzMLJWThJmZpXKSMDOzVE4SZmaWyknCzMxSOUmYmVkqJwkzM0vlJGFmZqmcJMzMLJWThJmZpXKSMDOzVE4SZmaWyknCzMxSOUmYmVkqJwkzM0vlJGFmZqmcJMzMLJWTRKLnQB+P7X6ZngN9jQ7FzKwwpjU6gCL4/tY9XLdxGy1NTfQPDnLL6mWsWj6/0WGZmTXclK9J9Bzo47qN2zjUP8grfQMc6h9k7cZtrlGYmeEkQXfvQVqahr8NLU1NdPcebFBENsRNgGaNN+WbmzrbZ9I/ODisrH9wkM72mQ2KyMBNgGZFMeVrEh1trVxe6hxWdnmpk4621gZFZG4CNCuOKZ8keg70saGre1jZhq5ufyE1kJsAzYpjyicJfyEVj5sAzYpjyicJfyEVT0dbK7esXsaMliZmtU5jRksTt6xe5iZAswaY8h3XQ19Ia0d0kvoLqbFWLZ/PirPn0t17kM72mf48zBpkyicJ8BdSUXW0tfqzMGuw3JubJK2U9JSknZKuH2X7VZL2Stqa3P64YtuVkp5JblfmGWdHWyvnLZjjLyUzswq51iQkNQPrgIuAbmCzpE0RsWPErndFxDUjjj0Z+AxQAgLYkhzbm2fMZmZ2VN41iQuAnRGxKyIOA3cCl1Z57HuAeyNiX5IY7gVW5hSnmZmNIu8kMR/YXfG4OykbabWkbZLulrSgxmPNzCwnRRgC+wNgYUQso1xbuL2WgyVdLalLUtfevXtzCdDMbKrKO0nsARZUPO5Myl4XET0RMXR589eBt1d7bHL8+ogoRURp3rx5mQVuZmb5J4nNwGJJiyRNB64ANlXuIOnUioergCeT+/cAF0tql9QOXJyUmZlZneQ6uikiBiRdQ/nLvRm4LSK2S7oJ6IqITcDHJa0CBoB9wFXJsfskfY5yogG4KSL25RmvmZkNp4hodAyZKZVK0dXV1egwzMwmFElbIqI02rYidFybmVlBOUmYmVkqJwkzM0vlJGFmNsHluR68Z4E1M5vA8l4P3jUJM7MJqh7rwTtJmJlNUPVYftlJwsxsgqrH8stOEmZmE1Q91oN3x7WZ2QSW9/LLrkmYmVkq1yTMzCYwD4E1M7NReQismZml8hBYMzNL5SGwZmaWykNgzcxsTHkPgXWSMDOb4DraWjNPDkPc3GRmZqmcJMzMLJWThJmZpXKSMDOzVE4SZmaWShHR6BgyI2kv8EKDw5gL/EuDYxhLkeMrcmzg+I5HkWODYsdXj9jOiIh5o22YVEmiCCR1RUSp0XGkKXJ8RY4NHN/xKHJsUOz4Gh2bm5vMzCyVk4SZmaVyksje+kYHMI4ix1fk2MDxHY8ixwbFjq+hsblPwszMUrkmYWZmqZwkzMwslZPEMZL0ryRtrbjtl/QJSZ+VtKei/JI6xnSbpF9JeqKi7GRJ90p6Jvm3PSmXpC9L2ilpm6S3NSi+L0n6eRLD30uak5QvlHSw4n38SoPiS/08Jd2QvH9PSXpPA2K7qyKu5yVtTcrr+t5JWiDpfkk7JG2XdG1SXohzb4z4CnHujRFfIc49IsK347wBzcAvgTOAzwL/pUFx/FvgbcATFWW3ANcn968HvpjcvwT4ESDgHcCjDYrvYmBacv+LFfEtrNyvge/fqJ8ncA7wGNAKLAKeBZrrGduI7bcCNzbivQNOBd6W3J8FPJ28P4U498aIrxDn3hjxFeLcc00iG78DPBsRDb3aOyIeBPaNKL4UuD25fzvwgYryO6LsEWCOpFPrHV9E/GNEDCQPHwE684xhLCnvX5pLgTsjoi8ingN2Ahc0IjZJAi4HvpPX648lIn4RET9N7r8CPAnMpyDnXlp8RTn3xnj/0tT13HOSyMYVDP8DvSapwt42VMVuoFMi4hfJ/V8CpyT35wO7K/brZuwTsx7+kPIvzCGLJP1M0gOS3tWooBj98yzS+/cu4KWIeKairCHvnaSFwPnAoxTw3BsRX6VCnHujxNfwc89J4jhJmg6sAr6bFP0NcBawHPgF5WaAQohyXbWQY54l/SkwAPxdUvQL4PSIOB9YA3xb0kkNCK2wn2eFjzD8R0pD3jtJbcBG4BMRsb9yWxHOvbT4inLujRJfIc49J4nj93vATyPiJYCIeCkijkTEIPA1cqwGVumloap88u+vkvI9wIKK/TqTsrqTdBXwPuDfJ18mJFXpnuT+FsrtrkvqHdsYn2ch3j9J04APAncNlTXivZPUQvkL7u8i4n8lxYU591LiK8y5N1p8RTn3nCSO37BfcSPaVv8d8MQbjqivTcCVyf0rge9XlP9BMtLkHcCvK5oG6kbSSmAtsCoiXqsonyepObl/JrAY2NWA+NI+z03AFZJaJS1K4vt/9Y4P+F3g5xHRPVRQ7/cu6RP5W+DJiPjLik2FOPfS4ivKuTdGfMU49/LqEZ8KN+BEoAeYXVH2LeBxYFvyYZ5ax3i+Q7la2k+5nfKPgA7g/wLPAP8HODnZV8A6yr+SHgdKDYpvJ+X21a3J7SvJvquB7UnZT4H3Nyi+1M8T+NPk/XsK+L16x5aUfxP4kxH71vW9A36DclPStorP8ZKinHtjxFeIc2+M+Apx7nlaDjMzS+XmJjMzS+UkYWZmqZwkzMwslZOEmZmlcpIwM7NUThJmZpbKScIsI5J+LKlUw/7LVcVU8pIOHF9kZsfOScKscZZTvmjKrLCcJMzGkCxA86SkryULwvyjpJljHPL7yQIxT0i6IHmOCyQ9nMwq+hOVF6yaDtwEfDjZ/8OS2iR9Q9Ljycyfqyvi+AtJj0l6RNIpaS9uljUnCbPxLQbWRcS5wMuUp21Ic0JELAf+A3BbUvZz4F1RnlX0RuDzEXE4uX9XRCyPiLuAT1Oex+itEbEMuC85/kTgkYg4D3gQ+FjG/39mqaY1OgCzCeC5iNia3N9CeeWyNN+B8iJBkk5SeUnMWcDtkhZTnqOnJeXY36W8NgnJc/Qmdw8D/1Dx+hcdy/+E2bFwTcJsfH0V948w9o+rkZOhBfA54P6IWAq8H5hR4+v3x9FJ1sZ7fbNMOUmYZevDAJJ+g3LT0a+B2Ryd7/+qin1foVzLGHIv8B+HHhRgVUMzJwmzjB2S9DPgK5SnGge4Bbg5Ka+sBdwPnDPUcQ38OdCedHo/BvxWPQM3G42nCjczs1SuSZiZWSp3gJnVSNI6YMWI4r+KiG80Ih6zPLm5yczMUrm5yczMUjlJmJlZKicJMzNL5SRhZmap/j88zPLcOOmCcgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "a6EePRwUD2aI",
        "outputId": "82afd66a-946c-4ee2-859c-27ae475c3e2c"
      },
      "source": [
        "# heatmap for the optimizer and batch size\n",
        "import seaborn as sns\n",
        "max_val_acc = hyperas_log.groupby(['n_batch', 'optim']).max()\n",
        "max_val_acc = max_val_acc.unstack()[['best_val_acc']]\n",
        "sns.heatmap(max_val_acc.best_val_acc, annot=True, fmt='.4g');\n",
        "b, t = plt.ylim()\n",
        "b += 0.5\n",
        "t -= 0.5\n",
        "plt.ylim(b, t)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.5, -0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}